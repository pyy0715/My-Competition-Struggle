{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_tutorial(5)_XG_Boost.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pyy0715/My-Kaggle-Struggle/blob/master/nlp_tutorial(5)_XG_Boost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V46pNlYDp0T",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "63bb5599-609e-437c-c07a-f5674cc9922a"
      },
      "source": [
        "# API Token 다운받기\n",
        "# 다운받은 API Token 업로드 하기\n",
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "# json 파일 옮겨주기\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "# Permission Warning 이 일어나지 않도록 \n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "# json 파일 제대로 업로드 됐는지 확인\n",
        "!ls -1ha kaggle.json\n",
        "# 데이터셋 다운로드 받기 - 링크는 그 대회 'Data'에 있음\n",
        "! kaggle competitions download -c word2vec-nlp-tutorial\n",
        "# 다운로드 된 것들 다 보기 \n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2fa1d30b-7291-45b4-abbe-f1ce7ad9111d\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-2fa1d30b-7291-45b4-abbe-f1ce7ad9111d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "kaggle.json\n",
            "Downloading sampleSubmission.csv to /content\n",
            "  0% 0.00/276k [00:00<?, ?B/s]\n",
            "100% 276k/276k [00:00<00:00, 76.0MB/s]\n",
            "Downloading unlabeledTrainData.tsv.zip to /content\n",
            " 35% 9.00M/26.0M [00:00<00:01, 13.5MB/s]\n",
            "100% 26.0M/26.0M [00:00<00:00, 33.4MB/s]\n",
            "Downloading testData.tsv.zip to /content\n",
            " 71% 9.00M/12.6M [00:00<00:00, 14.3MB/s]\n",
            "100% 12.6M/12.6M [00:00<00:00, 19.9MB/s]\n",
            "Downloading labeledTrainData.tsv.zip to /content\n",
            " 69% 9.00M/13.0M [00:00<00:00, 14.9MB/s]\n",
            "100% 13.0M/13.0M [00:00<00:00, 22.1MB/s]\n",
            "kaggle.json\t\t  sample_data\t\ttestData.tsv.zip\n",
            "labeledTrainData.tsv.zip  sampleSubmission.csv\tunlabeledTrainData.tsv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvBtcgnDDvPQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "07547ece-eda6-461f-b2ba-0c8bf7cc2cd2"
      },
      "source": [
        "!unzip labeledTrainData.tsv.zip\n",
        "!unzip testData.tsv.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  labeledTrainData.tsv.zip\n",
            "  inflating: labeledTrainData.tsv    \n",
            "Archive:  testData.tsv.zip\n",
            "  inflating: testData.tsv            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv5ZtSrpDvRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# 레이블인 sentiment 가 있는 학습 데이터\n",
        "train = pd.read_csv('labeledTrainData.tsv',header=0, delimiter='\\t', quoting=3)\n",
        "\n",
        "# 레이블이 없는 테스트 데이터\n",
        "test = pd.read_csv('testData.tsv', header=0, delimiter='\\t', quoting=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgRUIULsDvUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "from multiprocessing import Pool\n",
        "\n",
        "class KaggleWord2VecUtility(object):\n",
        "\n",
        "    @staticmethod\n",
        "    def review_to_wordlist(review, remove_stopwords=False):\n",
        "        # 1. HTML 제거\n",
        "        review_text = BeautifulSoup(review, \"html.parser\").get_text()\n",
        "        # 2. 특수문자를 공백으로 바꿔줌\n",
        "        review_text = re.sub('[^a-zA-Z]', ' ', review_text)\n",
        "        # 3. 소문자로 변환 후 나눈다.\n",
        "        words = review_text.lower().split()\n",
        "        # 4. 불용어 제거\n",
        "        if remove_stopwords:\n",
        "            stops = set(stopwords.words('english'))\n",
        "            words = [w for w in words if not w in stops]\n",
        "        # 5. 어간추출\n",
        "        stemmer = SnowballStemmer('english')\n",
        "        words = [stemmer.stem(w) for w in words]\n",
        "        # 6. 리스트 형태로 반환\n",
        "        return(words)\n",
        "\n",
        "    @staticmethod\n",
        "    def review_to_join_words( review, remove_stopwords=False ):\n",
        "        words = KaggleWord2VecUtility.review_to_wordlist(\\\n",
        "            review, remove_stopwords=False)\n",
        "        join_words = ' '.join(words)\n",
        "        return join_words\n",
        "\n",
        "    @staticmethod\n",
        "    def review_to_sentences( review, remove_stopwords=False ):\n",
        "        # punkt tokenizer를 로드한다.\n",
        "        \"\"\"\n",
        "        이 때, pickle을 사용하는데\n",
        "        pickle을 통해 값을 저장하면 원래 변수에 연결 된 참조값 역시 저장된다.\n",
        "        저장된 pickle을 다시 읽으면 변수에 연결되었던\n",
        "        모든 레퍼런스가 계속 참조 상태를 유지한다.\n",
        "        \"\"\"\n",
        "        tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "        # 1. nltk tokenizer를 사용해서 단어로 토큰화 하고 공백 등을 제거한다.\n",
        "        raw_sentences = tokenizer.tokenize(review.strip())\n",
        "        # 2. 각 문장을 순회한다.\n",
        "        sentences = []\n",
        "        for raw_sentence in raw_sentences:\n",
        "            # 비어있다면 skip\n",
        "            if len(raw_sentence) > 0:\n",
        "                # 태그제거, 알파벳문자가 아닌 것은 공백으로 치환, 불용어제거\n",
        "                sentences.append(\\\n",
        "                    KaggleWord2VecUtility.review_to_wordlist(\\\n",
        "                    raw_sentence, remove_stopwords))\n",
        "        return sentences\n",
        "\n",
        "\n",
        "    # 참고 : https://gist.github.com/yong27/7869662\n",
        "    # http://www.racketracer.com/2016/07/06/pandas-in-parallel/\n",
        "    # 속도 개선을 위해 멀티 스레드로 작업하도록\n",
        "    @staticmethod\n",
        "    def _apply_df(args):\n",
        "        df, func, kwargs = args\n",
        "        return df.apply(func, **kwargs)\n",
        "\n",
        "    @staticmethod\n",
        "    def apply_by_multiprocessing(df, func, **kwargs):\n",
        "        # 키워드 항목 중 workers 파라메터를 꺼냄\n",
        "        workers = kwargs.pop('workers')\n",
        "        # 위에서 가져온 workers 수로 프로세스 풀을 정의\n",
        "        pool = Pool(processes=workers)\n",
        "        # 실행할 함수와 데이터프레임을 워커의 수 만큼 나눠 작업\n",
        "        result = pool.map(KaggleWord2VecUtility._apply_df, [(d, func, kwargs)\n",
        "                for d in np.array_split(df, workers)])\n",
        "        pool.close()\n",
        "        # 작업 결과를 합쳐서 반환\n",
        "        return pd.concat(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgUMiWJODvWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def review_to_words( raw_review ):\n",
        "    review_text = BeautifulSoup(raw_review, 'html.parser').get_text()\n",
        "    review_text = wordnet_lemmatizer.lemmatize(review_text)\n",
        "    return review_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB1fasEiE4Lv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "21ce8eca-6c27-47da-e93f-de836f3f9b5f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGMc2LNbDvYu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3f7a9dd0-f415-4371-dedb-f93859b6d74d"
      },
      "source": [
        "# 학습데이터를 전처리 한다.\n",
        "%time train['review_clean'] = KaggleWord2VecUtility.apply_by_multiprocessing(\\\n",
        "    train['review'], review_to_words, workers=4)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 104 ms, sys: 123 ms, total: 227 ms\n",
            "Wall time: 7.18 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gVEG4pPDva2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8c898be0-9944-4bce-b5da-93e737c7713c"
      },
      "source": [
        "# 학습데이터와 동일하게 테스트 데이터에 대해서도 전처리 한다.\n",
        "%time test['review_clean'] = KaggleWord2VecUtility.apply_by_multiprocessing(\\\n",
        "    test['review'], review_to_words, workers=4)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 99.4 ms, sys: 119 ms, total: 219 ms\n",
            "Wall time: 6.98 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pnhix6qKFERe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train과 X_test에 리뷰 데이터를 담아주고 이 데이터를 TF-IDF를 통해 임베딩(벡터화)해본다. \n",
        "X_train = train['review_clean']\n",
        "X_test = test['review_clean']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S64hdzHFVB-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f1bbcd18-0479-44c1-c1b0-18c55aaeb965"
      },
      "source": [
        "nltk.download('words')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDva4HTfFEYr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "d69c383c-d12d-488f-a0c6-6bbadc8cb43d"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk.corpus import words\n",
        "\n",
        "vectorizer = CountVectorizer(analyzer = 'word', \n",
        "                             lowercase = True,\n",
        "                             tokenizer = None,\n",
        "                             preprocessor = None,\n",
        "                             stop_words = 'english',\n",
        "                             min_df = 2, # 토큰이 나타날 최소 문서 개수로 오타나 자주 나오지 않는 특수한 전문용어 제거에 좋다. \n",
        "                             ngram_range=(1, 3),\n",
        "                             vocabulary = set(words.words()), # nltk의 words를 사용하거나 문서 자체의 사전을 만들거나 선택한다. \n",
        "                             max_features = 90000\n",
        "                            )\n",
        "vectorizer"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=90000, min_df=2,\n",
              "                ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None,\n",
              "                vocabulary={'A', 'Aani', 'Aaron', 'Aaronic', 'Aaronical',\n",
              "                            'Aaronite', 'Aaronitic', 'Aaru', 'Ab', 'Ababdeh',\n",
              "                            'Ababua', 'Abadite', 'Abama', 'Abanic', 'Abantes',\n",
              "                            'Abarambo', 'Abaris', 'Abasgi', 'Abassin', 'Abatua',\n",
              "                            'Abba', 'Abbadide', 'Abbasside', 'Abbie', 'Abby',\n",
              "                            'Abderian', 'Abderite', 'Abdiel', 'Abdominales',\n",
              "                            'Abe', ...})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FCFWF0GFYq_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "e42af1c4-47f3-4c17-8039-85812eb7a4c8"
      },
      "source": [
        "pipeline = Pipeline([\n",
        "    ('vect', vectorizer),\n",
        "    ('tfidf', TfidfTransformer(smooth_idf = False)),\n",
        "])  \n",
        "pipeline"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=90000, min_df=2,\n",
              "                                 ngram_range=(1, 3), preprocessor=None,\n",
              "                                 stop_words='english', strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None,\n",
              "                                 vocabula...\n",
              "                                             'Aaronical', 'Aaronite',\n",
              "                                             'Aaronitic', 'Aaru', 'Ab',\n",
              "                                             'Ababdeh', 'Ababua', 'Abadite',\n",
              "                                             'Abama', 'Abanic', 'Abantes',\n",
              "                                             'Abarambo', 'Abaris', 'Abasgi',\n",
              "                                             'Abassin', 'Abatua', 'Abba',\n",
              "                                             'Abbadide', 'Abbasside', 'Abbie',\n",
              "                                             'Abby', 'Abderian', 'Abderite',\n",
              "                                             'Abdiel', 'Abdominales', 'Abe', ...})),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=False,\n",
              "                                  sublinear_tf=False, use_idf=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY75e4mXFEbx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "70bd8e76-8e4d-4599-bb4c-32205d0747aa"
      },
      "source": [
        "%time X_train_tfidf_vector = pipeline.fit_transform(X_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.76 s, sys: 33.6 ms, total: 6.8 s\n",
            "Wall time: 6.81 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:1278: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  idf = np.log(n_samples / df) + 1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wvUdaV6FEfH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "07395b55-18a2-4897-aa72-cd706051bb7f"
      },
      "source": [
        "vocab = vectorizer.get_feature_names()\n",
        "print(len(vocab))\n",
        "vocab[:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "235892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'Aani',\n",
              " 'Aaron',\n",
              " 'Aaronic',\n",
              " 'Aaronical',\n",
              " 'Aaronite',\n",
              " 'Aaronitic',\n",
              " 'Aaru',\n",
              " 'Ab',\n",
              " 'Ababdeh']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4JsQKA-FhFc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e3477239-75ca-4776-fc8a-a0859af171e1"
      },
      "source": [
        "%time X_test_tfidf_vector = pipeline.fit_transform(X_test)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.69 s, sys: 33.8 ms, total: 6.73 s\n",
            "Wall time: 6.73 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:1278: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  idf = np.log(n_samples / df) + 1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twGy8a3cFhLl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "e616beb1-e98d-4e8b-e5d4-a5d1e6fddcbd"
      },
      "source": [
        "dist = np.sum(X_train_tfidf_vector, axis=0)\n",
        "    \n",
        "for tag, count in zip(vocab, dist):\n",
        "    print(count, tag)\n",
        "    \n",
        "pd.DataFrame(dist, columns=vocab)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]] A\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>Aani</th>\n",
              "      <th>Aaron</th>\n",
              "      <th>Aaronic</th>\n",
              "      <th>Aaronical</th>\n",
              "      <th>Aaronite</th>\n",
              "      <th>Aaronitic</th>\n",
              "      <th>Aaru</th>\n",
              "      <th>Ab</th>\n",
              "      <th>Ababdeh</th>\n",
              "      <th>Ababua</th>\n",
              "      <th>Abadite</th>\n",
              "      <th>Abama</th>\n",
              "      <th>Abanic</th>\n",
              "      <th>Abantes</th>\n",
              "      <th>Abarambo</th>\n",
              "      <th>Abaris</th>\n",
              "      <th>Abasgi</th>\n",
              "      <th>Abassin</th>\n",
              "      <th>Abatua</th>\n",
              "      <th>Abba</th>\n",
              "      <th>Abbadide</th>\n",
              "      <th>Abbasside</th>\n",
              "      <th>Abbie</th>\n",
              "      <th>Abby</th>\n",
              "      <th>Abderian</th>\n",
              "      <th>Abderite</th>\n",
              "      <th>Abdiel</th>\n",
              "      <th>Abdominales</th>\n",
              "      <th>Abe</th>\n",
              "      <th>Abel</th>\n",
              "      <th>Abelia</th>\n",
              "      <th>Abelian</th>\n",
              "      <th>Abelicea</th>\n",
              "      <th>Abelite</th>\n",
              "      <th>Abelmoschus</th>\n",
              "      <th>Abelonian</th>\n",
              "      <th>Abencerrages</th>\n",
              "      <th>Aberdeen</th>\n",
              "      <th>Aberdonian</th>\n",
              "      <th>...</th>\n",
              "      <th>zymic</th>\n",
              "      <th>zymin</th>\n",
              "      <th>zymite</th>\n",
              "      <th>zymogen</th>\n",
              "      <th>zymogene</th>\n",
              "      <th>zymogenesis</th>\n",
              "      <th>zymogenic</th>\n",
              "      <th>zymogenous</th>\n",
              "      <th>zymoid</th>\n",
              "      <th>zymologic</th>\n",
              "      <th>zymological</th>\n",
              "      <th>zymologist</th>\n",
              "      <th>zymology</th>\n",
              "      <th>zymolyis</th>\n",
              "      <th>zymolysis</th>\n",
              "      <th>zymolytic</th>\n",
              "      <th>zymome</th>\n",
              "      <th>zymometer</th>\n",
              "      <th>zymomin</th>\n",
              "      <th>zymophore</th>\n",
              "      <th>zymophoric</th>\n",
              "      <th>zymophosphate</th>\n",
              "      <th>zymophyte</th>\n",
              "      <th>zymoplastic</th>\n",
              "      <th>zymoscope</th>\n",
              "      <th>zymosimeter</th>\n",
              "      <th>zymosis</th>\n",
              "      <th>zymosterol</th>\n",
              "      <th>zymosthenic</th>\n",
              "      <th>zymotechnic</th>\n",
              "      <th>zymotechnical</th>\n",
              "      <th>zymotechnics</th>\n",
              "      <th>zymotechny</th>\n",
              "      <th>zymotic</th>\n",
              "      <th>zymotically</th>\n",
              "      <th>zymotize</th>\n",
              "      <th>zymotoxic</th>\n",
              "      <th>zymurgy</th>\n",
              "      <th>zythem</th>\n",
              "      <th>zythum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 235892 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     A  Aani  Aaron  Aaronic  ...  zymotoxic  zymurgy  zythem  zythum\n",
              "0  0.0   0.0    0.0      0.0  ...        0.0      0.0     0.0     0.0\n",
              "\n",
              "[1 rows x 235892 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAEpXG5NHXbn",
        "colab_type": "text"
      },
      "source": [
        "# XG_Boost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp--LuTrFhOZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "6a7c820a-2095-4b9c-bf33-b99572823e0e"
      },
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train_tfidf_vector, label=train['sentiment'])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n",
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  data.base is not None and isinstance(data, np.ndarray) \\\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR8Z3WIiMV4N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a6193174-4203-4cfa-9562-28c8b0963de3"
      },
      "source": [
        "# 멀티프로세싱은 nthread 였는데 n_jobs로 변경되었다고 한다.\n",
        "# 설치 된 xgboost버전에 따라 파라메터가 다를 수 있으니 \n",
        "# 이 코드를 돌리고 터미널에서 $ top -o cpu 로 CPU자원을 100%넘게 사용하고 있는지 확인해 본다.\n",
        "params = {\n",
        "    'booster': 'gbtree',\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'auc',\n",
        "    'max_depth' : 7,\n",
        "    'n_jobs' : 4\n",
        "}\n",
        "\n",
        "%time booster = xgb.train(params, dtrain, num_boost_round=300)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7min 21s, sys: 121 ms, total: 7min 22s\n",
            "Wall time: 3min 43s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wj64u6gDvfq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "3815a088-e363-41c6-84b8-913c90f65168"
      },
      "source": [
        "dtest = xgb.DMatrix(X_test_tfidf_vector)\n",
        "\n",
        "result = booster.predict(dtest)\n",
        "\n",
        "print(result.shape)\n",
        "result[0:10]"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.8691911e-01, 5.1436871e-03, 8.7154359e-01, 7.0893699e-01,\n",
              "       8.4170997e-01, 1.2150814e-01, 1.3488032e-02, 5.3440422e-01,\n",
              "       4.1205288e-04, 4.3966568e-01], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq95rYOiHvCM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "ff434eb4-4697-4cff-88df-c88c70bbd9e4"
      },
      "source": [
        "output = pd.DataFrame(data={'id':test['id'], 'sentiment':result})\n",
        "output.head()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"12311_10\"</td>\n",
              "      <td>0.986919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"8348_2\"</td>\n",
              "      <td>0.005144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"5828_4\"</td>\n",
              "      <td>0.871544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"7186_2\"</td>\n",
              "      <td>0.708937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"12128_7\"</td>\n",
              "      <td>0.841710</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  sentiment\n",
              "0  \"12311_10\"   0.986919\n",
              "1    \"8348_2\"   0.005144\n",
              "2    \"5828_4\"   0.871544\n",
              "3    \"7186_2\"   0.708937\n",
              "4   \"12128_7\"   0.841710"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHUNJelhNfKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output['sentiment']=np.where(output['sentiment']>=0.5,1,0)\n",
        "\n",
        "output['sentiment'] = output['sentiment'].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lj_07YRHvFo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "251310d1-9ab6-4811-9d1d-fed796cc48a0"
      },
      "source": [
        "output['sentiment'].value_counts()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    12765\n",
              "0    12235\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmY4gn34HvKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output.to_csv(\"tutorial_5_xgboost.csv\", index=False, quoting=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VJ7L1TUDvkZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7705fb22-c9e1-43ff-fd93-02c66cb9a053"
      },
      "source": [
        "!kaggle competitions submit -c word2vec-nlp-tutorial -f tutorial_5_xgboost.csv -m 'max_depth=7,num=300'"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 276k/276k [00:14<00:00, 19.4kB/s]\n",
            "Successfully submitted to Bag of Words Meets Bags of Popcorn"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_lxYwAfOzLe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "5eae25ba-6b2b-435f-c1fc-8f3293108afe"
      },
      "source": [
        "!kaggle competitions submissions -c word2vec-nlp-tutorial"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fileName                      date                 description                 status    publicScore  privateScore  \n",
            "----------------------------  -------------------  --------------------------  --------  -----------  ------------  \n",
            "tutorial_5_xgboost.csv        2019-06-03 07:44:36  max_depth=7                 complete  0.85540      None          \n",
            "tutorial_5_xgboost.csv        2019-06-03 07:43:23  max_depth=7                 complete  0.85540      None          \n",
            "tutorial_5_xgboost.csv        2019-06-03 07:36:51  num_boost_round=300         complete  0.80500      None          \n",
            "tutorial_5_xgboost.csv        2019-06-03 07:26:23  num_boost_round=100         complete  0.76156      None          \n",
            "tutorial_4_tfidf_0.92051.csv  2019-06-02 20:56:51  None                        complete  0.84388      None          \n",
            "bag of words                  2019-05-27 09:54:19  From \"bag of words\" Script  complete  0.81792      None          \n",
            "bag of words                  2019-05-27 09:52:35  From \"bag of words\" Script  complete  0.82924      None          \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
