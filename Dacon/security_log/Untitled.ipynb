{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:13:08.083305Z",
     "start_time": "2021-05-14T06:13:08.036479Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, log_loss, recall_score, f1_score, classification_report\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T05:03:12.101841Z",
     "start_time": "2021-05-14T05:03:05.699963Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./dataset/train.csv')\n",
    "test_df = pd.read_csv('./dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T05:03:12.105508Z",
     "start_time": "2021-05-14T05:03:12.102845Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    x = x.lower()\n",
    "    x = re.sub(f'[0-9]', 'N', x)\n",
    "    x = re.sub(r'(\\\\n)', ' ', x)\n",
    "    x = re.sub(r',', ' ', x)\n",
    "    x = re.sub(r'[^a-zA-Zㄱ-ㅣ가-힣\\s]+', '',x)\n",
    "    x = re.sub(r'N', '', x)\n",
    "    x = re.sub(r'jan|feb|oct|dec|mar|nov|sep', '', x)\n",
    "    x = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', x) \n",
    "    x = re.sub(r'\\s+', ' ', x)\n",
    "    return x.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T05:05:17.432785Z",
     "start_time": "2021-05-14T05:03:35.139126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 42s, sys: 176 ms, total: 1min 42s\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_df['clean_log'] = train_df['full_log'].map(lambda x: clean(x))\n",
    "test_df['clean_log'] = test_df['full_log'].map(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T05:05:21.530151Z",
     "start_time": "2021-05-14T05:05:21.526956Z"
    }
   },
   "outputs": [],
   "source": [
    "def truncated_string(x, max_length):\n",
    "    arr = []\n",
    "    idx = max_length//2\n",
    "    token_list = x.split(' ')\n",
    "    if len(token_list)>max_length:\n",
    "        arr+=token_list[:idx]\n",
    "        arr+=token_list[-idx:]\n",
    "    else:\n",
    "        arr+=token_list\n",
    "    return ' '.join(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T05:05:24.879543Z",
     "start_time": "2021-05-14T05:05:21.927595Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['sample_word'] = train_df['clean_log'].map(lambda x: truncated_string(x, 64))\n",
    "test_df['sample_word'] = test_df['clean_log'].map(lambda x: truncated_string(x, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:52:12.706886Z",
     "start_time": "2021-05-14T06:52:12.695818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>level</th>\n",
       "      <th>full_log</th>\n",
       "      <th>clean_log</th>\n",
       "      <th>sample_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sep 24 10:02:22 localhost kibana: {\"type\":\"err...</td>\n",
       "      <td>localhost kibana typeerror timestamptz tagswar...</td>\n",
       "      <td>localhost kibana typeerror timestamptz tagswar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Feb  8 16:21:00 localhost logstash: [2021-02-0...</td>\n",
       "      <td>localhost logstash info logstashoutputselastic...</td>\n",
       "      <td>localhost logstash info logstashoutputselastic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan 13 01:50:40 localhost kibana: {\"type\":\"err...</td>\n",
       "      <td>localhost kibana typeerror timestamptz tagswar...</td>\n",
       "      <td>localhost kibana typeerror timestamptz tagswar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan  4 10:18:31 localhost kibana: {\"type\":\"err...</td>\n",
       "      <td>localhost kibana typeerror timestamptz tagswar...</td>\n",
       "      <td>localhost kibana typeerror timestamptz tagswar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>type=SYSCALL msg=audit(1603094402.016:52981): ...</td>\n",
       "      <td>typesyscall msgaudit archce syscall successyes...</td>\n",
       "      <td>typesyscall msgaudit archce syscall successyes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  level                                           full_log  \\\n",
       "0   0      0  Sep 24 10:02:22 localhost kibana: {\"type\":\"err...   \n",
       "1   1      0  Feb  8 16:21:00 localhost logstash: [2021-02-0...   \n",
       "2   2      0  Jan 13 01:50:40 localhost kibana: {\"type\":\"err...   \n",
       "3   3      0  Jan  4 10:18:31 localhost kibana: {\"type\":\"err...   \n",
       "4   4      1  type=SYSCALL msg=audit(1603094402.016:52981): ...   \n",
       "\n",
       "                                           clean_log  \\\n",
       "0  localhost kibana typeerror timestamptz tagswar...   \n",
       "1  localhost logstash info logstashoutputselastic...   \n",
       "2  localhost kibana typeerror timestamptz tagswar...   \n",
       "3  localhost kibana typeerror timestamptz tagswar...   \n",
       "4  typesyscall msgaudit archce syscall successyes...   \n",
       "\n",
       "                                         sample_word  \n",
       "0  localhost kibana typeerror timestamptz tagswar...  \n",
       "1  localhost logstash info logstashoutputselastic...  \n",
       "2  localhost kibana typeerror timestamptz tagswar...  \n",
       "3  localhost kibana typeerror timestamptz tagswar...  \n",
       "4  typesyscall msgaudit archce syscall successyes...  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:30:26.693623Z",
     "start_time": "2021-05-14T07:30:26.409851Z"
    }
   },
   "outputs": [],
   "source": [
    "train_drop_df = train_df[['level','clean_log']].drop_duplicates().reset_index(drop=True)\n",
    "train_drop_df['doc_idx'] = train_drop_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:30:27.414340Z",
     "start_time": "2021-05-14T07:30:27.041920Z"
    }
   },
   "outputs": [],
   "source": [
    "train_drop_df[['clean_log', 'doc_idx']].to_csv('sample.txt', sep = '\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:30:27.703587Z",
     "start_time": "2021-05-14T07:30:27.696020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>clean_log</th>\n",
       "      <th>doc_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>localhost kibana typeerror timestamptz tagswar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>localhost logstash info logstashoutputselastic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>typesyscall msgaudit archce syscall successyes...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>typesyscall msgaudit archce syscall successyes...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>localhost logstash warn logstashoutputselastic...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>localhost kibana typelog timestamptz tagswarni...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>typesyscall msgaudit archce syscall successyes...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>localhost logstash warn logstashoutputselastic...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>localhost logstash rufusscheduler intercepted ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>typesyscall msgaudit archce syscall successyes...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level                                          clean_log  doc_idx\n",
       "0      0  localhost kibana typeerror timestamptz tagswar...        0\n",
       "1      0  localhost logstash info logstashoutputselastic...        1\n",
       "2      1  typesyscall msgaudit archce syscall successyes...        2\n",
       "3      1  typesyscall msgaudit archce syscall successyes...        3\n",
       "4      0  localhost logstash warn logstashoutputselastic...        4\n",
       "5      0  localhost kibana typelog timestamptz tagswarni...        5\n",
       "6      1  typesyscall msgaudit archce syscall successyes...        6\n",
       "7      0  localhost logstash warn logstashoutputselastic...        7\n",
       "8      0  localhost logstash rufusscheduler intercepted ...        8\n",
       "9      1  typesyscall msgaudit archce syscall successyes...        9"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_drop_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:30:28.570363Z",
     "start_time": "2021-05-14T07:30:28.566439Z"
    }
   },
   "outputs": [],
   "source": [
    "class Doc2VecCorpus:\n",
    "    def __init__(self, fname):\n",
    "        self.fname = fname\n",
    "    def __iter__(self):\n",
    "        with open(self.fname, encoding='utf-8') as f:\n",
    "            for doc in f:\n",
    "                text, doc_idx = doc.split('\\t')\n",
    "                yield TaggedDocument(\n",
    "                    words = text.split(' '), \n",
    "                    tags = ['Doc_%s' % doc_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:30:29.478386Z",
     "start_time": "2021-05-14T07:30:29.475724Z"
    }
   },
   "outputs": [],
   "source": [
    "doc2vec_corpus = Doc2VecCorpus('./sample.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:30:38.279662Z",
     "start_time": "2021-05-14T07:30:38.270699Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec(vector_size = 128, \n",
    "                window = 2, \n",
    "                dm = 1,\n",
    "                min_count = 2, \n",
    "                negative = 5,\n",
    "                workers = 6, \n",
    "                seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:30:41.251431Z",
     "start_time": "2021-05-14T07:30:40.241008Z"
    }
   },
   "outputs": [],
   "source": [
    "model.build_vocab(doc2vec_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:33:02.448301Z",
     "start_time": "2021-05-14T07:30:41.252556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 54s, sys: 28 s, total: 3min 22s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.train(doc2vec_corpus, total_examples=model.corpus_count, epochs=30)\n",
    "model.save(\"d2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:24:25.663839Z",
     "start_time": "2021-05-14T07:24:25.651797Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Doc_4\\n', 0.9999998807907104),\n",
       " ('Doc_7\\n', 0.9872230291366577),\n",
       " ('Doc_9169\\n', 0.9686447381973267),\n",
       " ('Doc_28775\\n', 0.9613114595413208),\n",
       " ('Doc_22314\\n', 0.956368625164032),\n",
       " ('Doc_20649\\n', 0.9459691047668457),\n",
       " ('Doc_7537\\n', 0.9424419403076172),\n",
       " ('Doc_552\\n', 0.9419867396354675),\n",
       " ('Doc_8963\\n', 0.9391908645629883),\n",
       " ('Doc_44001\\n', 0.9324362874031067)]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = model.dv[4]\n",
    "model.dv.most_similar([sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:25:05.848811Z",
     "start_time": "2021-05-14T07:25:05.696109Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "635808d83a0848f085aab354770639b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54248 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_features = []\n",
    "\n",
    "for i in tqdm(range(len(train_drop_df))):\n",
    "    train_features.append(model.dv[i])\n",
    "    \n",
    "train_features = np.array(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:30:01.705909Z",
     "start_time": "2021-05-14T07:30:01.702814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54248, 128)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:25:23.279226Z",
     "start_time": "2021-05-14T07:25:23.276247Z"
    }
   },
   "outputs": [],
   "source": [
    "train_level = train_drop_df['level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:25:45.681601Z",
     "start_time": "2021-05-14T07:25:23.653747Z"
    }
   },
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.3\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "train_x, eval_x, train_y, eval_y = train_test_split(train_features, train_level,\n",
    "                                                    stratify = train_level,\n",
    "                                                    shuffle = True,\n",
    "                                                    test_size=TEST_SIZE, \n",
    "                                                    random_state=RANDOM_SEED)\n",
    "\n",
    "clf = LogisticRegression(random_state=42,\n",
    "                         solver='newton-cg',\n",
    "                         max_iter=1000,\n",
    "                         n_jobs=-1)\n",
    "\n",
    "clf.fit(train_x, train_y)\n",
    "clf_pred = clf.predict_proba(eval_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:25:56.860001Z",
     "start_time": "2021-05-14T07:25:56.841913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy score: 0.95177 \n",
      "CV Precision score: 0.39832 \n",
      "CV Recall score: 0.28049 \n",
      "CV F1 score: 0.29618 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yyeon/anaconda3/envs/DL_Server/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"CV Accuracy score: {:<8.5f}\".format(accuracy_score(eval_y, np.argmax(clf_pred, axis=1))))\n",
    "print(\"CV Precision score: {:<8.5f}\".format(precision_score(eval_y, np.argmax(clf_pred, axis=1), average='macro')))\n",
    "print(\"CV Recall score: {:<8.5f}\".format(recall_score(eval_y, np.argmax(clf_pred, axis=1), average='macro')))\n",
    "print(\"CV F1 score: {:<8.5f}\".format(f1_score(eval_y, np.argmax(clf_pred, axis=1), average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:29:34.219599Z",
     "start_time": "2021-05-14T07:29:34.199233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.68      0.66       922\n",
      "           1       0.97      0.99      0.98     15004\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.62      0.05      0.09       157\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.56      0.24      0.34       189\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.95     16275\n",
      "   macro avg       0.40      0.28      0.30     16275\n",
      "weighted avg       0.95      0.95      0.95     16275\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yyeon/anaconda3/envs/DL_Server/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yyeon/anaconda3/envs/DL_Server/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/yyeon/anaconda3/envs/DL_Server/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(eval_y, np.argmax(clf_pred, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:04:39.898499Z",
     "start_time": "2021-05-14T07:04:39.895101Z"
    }
   },
   "outputs": [],
   "source": [
    "param = {'boosting_type':'gbdt',\n",
    "         'max_depth':7, \n",
    "         'num_leaves':31,\n",
    "         'objective': 'multi-class',\n",
    "         'n_estimators':1000, \n",
    "         'learning_rate':0.01, \n",
    "         'subsample':0.8, \n",
    "         'colsample_bytree':0.8,\n",
    "         'num_class': 7,\n",
    "#          'reg_alpha':0.5, \n",
    "#          'reg_lambda':1.0, \n",
    "         'random_state':42\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:29:06.580955Z",
     "start_time": "2021-05-14T07:27:01.177174Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yyeon/anaconda3/envs/DL_Server/lib/python3.8/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fold num_: 0\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's multi_logloss: 0.12812\tvalid_1's multi_logloss: 0.146385\n",
      "[100]\ttraining's multi_logloss: 0.0811647\tvalid_1's multi_logloss: 0.103388\n",
      "[150]\ttraining's multi_logloss: 0.0601368\tvalid_1's multi_logloss: 0.0852644\n",
      "[200]\ttraining's multi_logloss: 0.0485861\tvalid_1's multi_logloss: 0.0761708\n",
      "[250]\ttraining's multi_logloss: 0.0407011\tvalid_1's multi_logloss: 0.0706806\n",
      "[300]\ttraining's multi_logloss: 0.0345743\tvalid_1's multi_logloss: 0.0671128\n",
      "[350]\ttraining's multi_logloss: 0.029644\tvalid_1's multi_logloss: 0.0646896\n",
      "[400]\ttraining's multi_logloss: 0.0252796\tvalid_1's multi_logloss: 0.0629707\n",
      "[450]\ttraining's multi_logloss: 0.0217325\tvalid_1's multi_logloss: 0.0618195\n",
      "[500]\ttraining's multi_logloss: 0.0186908\tvalid_1's multi_logloss: 0.0611104\n",
      "[550]\ttraining's multi_logloss: 0.0161452\tvalid_1's multi_logloss: 0.060773\n",
      "[600]\ttraining's multi_logloss: 0.0139204\tvalid_1's multi_logloss: 0.060651\n",
      "[650]\ttraining's multi_logloss: 0.0120357\tvalid_1's multi_logloss: 0.0606555\n",
      "Early stopping, best iteration is:\n",
      "[616]\ttraining's multi_logloss: 0.0132824\tvalid_1's multi_logloss: 0.0606191\n",
      "\n",
      "fold num_: 1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's multi_logloss: 0.127349\tvalid_1's multi_logloss: 0.144742\n",
      "[100]\ttraining's multi_logloss: 0.0804913\tvalid_1's multi_logloss: 0.101926\n",
      "[150]\ttraining's multi_logloss: 0.0596013\tvalid_1's multi_logloss: 0.0836674\n",
      "[200]\ttraining's multi_logloss: 0.0483996\tvalid_1's multi_logloss: 0.0745143\n",
      "[250]\ttraining's multi_logloss: 0.0409144\tvalid_1's multi_logloss: 0.0692171\n",
      "[300]\ttraining's multi_logloss: 0.0348768\tvalid_1's multi_logloss: 0.0658465\n",
      "[350]\ttraining's multi_logloss: 0.0297961\tvalid_1's multi_logloss: 0.0633936\n",
      "[400]\ttraining's multi_logloss: 0.0256005\tvalid_1's multi_logloss: 0.0618198\n",
      "[450]\ttraining's multi_logloss: 0.021978\tvalid_1's multi_logloss: 0.0606136\n",
      "[500]\ttraining's multi_logloss: 0.0188402\tvalid_1's multi_logloss: 0.0598807\n",
      "[550]\ttraining's multi_logloss: 0.0161245\tvalid_1's multi_logloss: 0.0593819\n",
      "[600]\ttraining's multi_logloss: 0.0138605\tvalid_1's multi_logloss: 0.0591095\n",
      "[650]\ttraining's multi_logloss: 0.0120333\tvalid_1's multi_logloss: 0.0589523\n",
      "[700]\ttraining's multi_logloss: 0.0104499\tvalid_1's multi_logloss: 0.0590546\n",
      "Early stopping, best iteration is:\n",
      "[650]\ttraining's multi_logloss: 0.0120333\tvalid_1's multi_logloss: 0.0589523\n",
      "\n",
      "fold num_: 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's multi_logloss: 0.128058\tvalid_1's multi_logloss: 0.146213\n",
      "[100]\ttraining's multi_logloss: 0.0812822\tvalid_1's multi_logloss: 0.103764\n",
      "[150]\ttraining's multi_logloss: 0.0604474\tvalid_1's multi_logloss: 0.0860478\n",
      "[200]\ttraining's multi_logloss: 0.0488779\tvalid_1's multi_logloss: 0.0772228\n",
      "[250]\ttraining's multi_logloss: 0.0412455\tvalid_1's multi_logloss: 0.0722621\n",
      "[300]\ttraining's multi_logloss: 0.0349911\tvalid_1's multi_logloss: 0.0689614\n",
      "[350]\ttraining's multi_logloss: 0.0295435\tvalid_1's multi_logloss: 0.0667126\n",
      "[400]\ttraining's multi_logloss: 0.0248987\tvalid_1's multi_logloss: 0.0650056\n",
      "[450]\ttraining's multi_logloss: 0.0211645\tvalid_1's multi_logloss: 0.0639038\n",
      "[500]\ttraining's multi_logloss: 0.0181491\tvalid_1's multi_logloss: 0.0632528\n",
      "[550]\ttraining's multi_logloss: 0.0156095\tvalid_1's multi_logloss: 0.062798\n",
      "[600]\ttraining's multi_logloss: 0.0133851\tvalid_1's multi_logloss: 0.0625776\n",
      "[650]\ttraining's multi_logloss: 0.0115458\tvalid_1's multi_logloss: 0.0626026\n",
      "Early stopping, best iteration is:\n",
      "[610]\ttraining's multi_logloss: 0.0129945\tvalid_1's multi_logloss: 0.062563\n",
      "\n",
      "fold num_: 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's multi_logloss: 0.127867\tvalid_1's multi_logloss: 0.143141\n",
      "[100]\ttraining's multi_logloss: 0.0810518\tvalid_1's multi_logloss: 0.100244\n",
      "[150]\ttraining's multi_logloss: 0.0601507\tvalid_1's multi_logloss: 0.0823706\n",
      "[200]\ttraining's multi_logloss: 0.0486327\tvalid_1's multi_logloss: 0.0735315\n",
      "[250]\ttraining's multi_logloss: 0.0409567\tvalid_1's multi_logloss: 0.0683071\n",
      "[300]\ttraining's multi_logloss: 0.0350572\tvalid_1's multi_logloss: 0.0649884\n",
      "[350]\ttraining's multi_logloss: 0.0300382\tvalid_1's multi_logloss: 0.0626467\n",
      "[400]\ttraining's multi_logloss: 0.0257266\tvalid_1's multi_logloss: 0.0610825\n",
      "[450]\ttraining's multi_logloss: 0.022016\tvalid_1's multi_logloss: 0.0598695\n",
      "[500]\ttraining's multi_logloss: 0.0188269\tvalid_1's multi_logloss: 0.0591547\n",
      "[550]\ttraining's multi_logloss: 0.0161224\tvalid_1's multi_logloss: 0.058601\n",
      "[600]\ttraining's multi_logloss: 0.0138564\tvalid_1's multi_logloss: 0.058393\n",
      "[650]\ttraining's multi_logloss: 0.011954\tvalid_1's multi_logloss: 0.0583179\n",
      "[700]\ttraining's multi_logloss: 0.010313\tvalid_1's multi_logloss: 0.058379\n",
      "Early stopping, best iteration is:\n",
      "[669]\ttraining's multi_logloss: 0.0113055\tvalid_1's multi_logloss: 0.0582958\n",
      "\n",
      "fold num_: 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's multi_logloss: 0.128032\tvalid_1's multi_logloss: 0.147803\n",
      "[100]\ttraining's multi_logloss: 0.0810459\tvalid_1's multi_logloss: 0.103645\n",
      "[150]\ttraining's multi_logloss: 0.0601629\tvalid_1's multi_logloss: 0.0845431\n",
      "[200]\ttraining's multi_logloss: 0.04854\tvalid_1's multi_logloss: 0.0750469\n",
      "[250]\ttraining's multi_logloss: 0.0407875\tvalid_1's multi_logloss: 0.0696048\n",
      "[300]\ttraining's multi_logloss: 0.034943\tvalid_1's multi_logloss: 0.0658922\n",
      "[350]\ttraining's multi_logloss: 0.0297451\tvalid_1's multi_logloss: 0.0631854\n",
      "[400]\ttraining's multi_logloss: 0.0254413\tvalid_1's multi_logloss: 0.0613939\n",
      "[450]\ttraining's multi_logloss: 0.0218876\tvalid_1's multi_logloss: 0.0603459\n",
      "[500]\ttraining's multi_logloss: 0.018773\tvalid_1's multi_logloss: 0.0595013\n",
      "[550]\ttraining's multi_logloss: 0.016112\tvalid_1's multi_logloss: 0.0589947\n",
      "[600]\ttraining's multi_logloss: 0.0138522\tvalid_1's multi_logloss: 0.0587899\n",
      "[650]\ttraining's multi_logloss: 0.0118886\tvalid_1's multi_logloss: 0.0587762\n",
      "Early stopping, best iteration is:\n",
      "[620]\ttraining's multi_logloss: 0.0130252\tvalid_1's multi_logloss: 0.0587353\n",
      "\n",
      "Cross Validation Is Complete\n",
      "CV Accuracy score: 0.97731 \n",
      "CV Precision score: 0.50302 \n",
      "CV Recall score: 0.45283 \n",
      "CV F1 score: 0.47103 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yyeon/anaconda3/envs/DL_Server/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "oof_lgb = np.zeros((len(train_drop_df), 7))\n",
    "# lgb_pred = np.zeros((len(test_df), 7))\n",
    "# eval_results = np.zeros((3, 7))\n",
    "\n",
    "# valid_df = pd.read_csv('./dataset/validation_sample.csv')\n",
    "# valid_df['clean_log'] = valid_df['full_log'].map(lambda x: clean(x))\n",
    "# valid_df['first_word'] = valid_df['clean_log'].map(lambda x: truncated_string(x, 64))\n",
    "# valid_text=valid_df['first_word'].to_list()\n",
    "# valid_features=vectorizer3.transform(valid_text)\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(skf.split(train_features, train_level)):\n",
    "    print(\"\\nfold num_: {}\".format(fold_))\n",
    "    y_train, y_valid = train_level[trn_idx], train_level[val_idx]\n",
    "    X_train, X_valid = train_features[trn_idx], train_features[val_idx]\n",
    "    \n",
    "    clf = LGBMClassifier(**param)\n",
    "    clf.fit(X_train, y_train, \n",
    "            eval_set=[(X_train, y_train), (X_valid, y_valid)], \n",
    "            early_stopping_rounds=50,\n",
    "            verbose=50)\n",
    "    \n",
    "    oof_lgb[val_idx] = clf.predict_proba(X_valid, num_iteration=clf.best_iteration_)   \n",
    "#     eval_results += clf.predict_proba(valid_features, num_iteration=clf.best_iteration_)\n",
    "#     lgb_pred += clf.predict_proba(test_features, num_iteration=clf.best_iteration_)\n",
    "\n",
    "# eval_results /= 2\n",
    "# lgb_pred /= 5    \n",
    "print('\\nCross Validation Is Complete')\n",
    "print(\"CV Accuracy score: {:<8.5f}\".format(accuracy_score(train_level, np.argmax(oof_lgb, axis=1))))\n",
    "print(\"CV Precision score: {:<8.5f}\".format(precision_score(train_level, np.argmax(oof_lgb, axis=1), average='macro')))\n",
    "print(\"CV Recall score: {:<8.5f}\".format(recall_score(train_level, np.argmax(oof_lgb, axis=1), average='macro')))\n",
    "print(\"CV F1 score: {:<8.5f}\".format(f1_score(train_level, np.argmax(oof_lgb, axis=1), average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:00:24.850076Z",
     "start_time": "2021-05-14T06:00:24.846749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     3, ..., 54244, 54246, 54247])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_Server",
   "language": "python",
   "name": "dl_server"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
