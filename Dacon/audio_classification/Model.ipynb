{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T15:30:26.257419Z",
     "start_time": "2021-06-10T15:30:26.250649Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, log_loss, f1_score\n",
    "\n",
    "import librosa\n",
    "from audiomentations import Compose, AddGaussianNoise, Shift, TimeStretch, PitchShift\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T15:30:26.536412Z",
     "start_time": "2021-06-10T15:30:26.534389Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = './dataset'\n",
    "train_npy_dir = './dataset/train_npy'\n",
    "test_npy_dir = './dataset/test_npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T15:30:26.850869Z",
     "start_time": "2021-06-10T15:30:26.842186Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(os.path.join(data_dir, 'new_train.pkl'))\n",
    "test_df = pd.read_pickle(os.path.join(data_dir, 'test.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T15:30:41.634808Z",
     "start_time": "2021-06-10T15:30:41.627128Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2021"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict({'sr': 16000,\n",
    "                          'n_mels': 128,\n",
    "                          'n_fft': [1024],\n",
    "                          'win_length': [600],\n",
    "                          'hop_length':120,\n",
    "                          'min_length': 120000,\n",
    "                          'min_level_db': -80,\n",
    "                          'lr': 1e-4,\n",
    "                          'epochs':20,\n",
    "                          'seed': 2021,\n",
    "                          'batch_num':32,\n",
    "                          'fp16': True\n",
    "})\n",
    "\n",
    "pl.seed_everything(args['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T18:14:22.215232Z",
     "start_time": "2021-06-08T18:14:19.212Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def get_length(path_list):\n",
    "#     length = []\n",
    "#     for i in tqdm(path_list):\n",
    "#         audio = np.load(i)\n",
    "#         length.append(audio.shape[0])\n",
    "#     return length\n",
    "\n",
    "# train_length = get_length(train_df['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T06:45:12.746718Z",
     "start_time": "2021-06-09T06:45:12.726694Z"
    }
   },
   "outputs": [],
   "source": [
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, hparams, csv, transform=None):\n",
    "        self.hparams = hparams\n",
    "        self.csv = csv.reset_index(drop=True)\n",
    "        self.aug = Compose([AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "                            TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "                            PitchShift(min_semitones=-4,\n",
    "                                       max_semitones=4, p=0.5),\n",
    "                            Shift(min_fraction=-0.5, max_fraction=0.5, p=0.5)])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "    \n",
    "    def generate_mel(self, audio, sr, n_fft, win_length, hop_length, n_mels):\n",
    "        S = librosa.feature.melspectrogram(y=audio,\n",
    "                                           sr=sr,\n",
    "                                           n_fft=n_fft,\n",
    "                                           win_length=win_length,\n",
    "                                           hop_length=hop_length,\n",
    "                                           n_mels=n_mels)\n",
    "        S = librosa.power_to_db(S, ref=np.max)\n",
    "        S = np.clip((S - self.hparams.min_level_db) / -\n",
    "                    self.hparams.min_level_db, 0, 1)\n",
    "        return S\n",
    "    \n",
    "    def features_extractor(self, audio_path):\n",
    "        audio = np.load(audio_path)\n",
    "        audio = librosa.util.fix_length(audio, self.hparams.min_length)\n",
    "        \n",
    "        if self.transform:\n",
    "            audio = self.aug(audio, sample_rate=self.hparams.sr)\n",
    "\n",
    "        mel = []\n",
    "        for n_fft, win_length in zip(self.hparams.n_fft, self.hparams.win_length):\n",
    "            S = self.generate_mel(audio,\n",
    "                                  self.hparams.sr,\n",
    "                                  n_fft, win_length, self.hparams.hop_length,\n",
    "                                  self.hparams.n_mels)\n",
    "            mel.append(S)\n",
    "        return np.array(mel)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.csv.iloc[index, -1]\n",
    "        label = self.csv.iloc[index, 1]\n",
    "        mel = self.features_extractor(path)\n",
    "        return (\n",
    "            torch.tensor(mel, dtype=torch.float),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T15:32:00.525597Z",
     "start_time": "2021-06-10T15:32:00.519719Z"
    }
   },
   "outputs": [],
   "source": [
    "class audio_resnet34(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.org_model = torchvision.models.resnet34()\n",
    "        self.org_model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.features = nn.Sequential(*(list(self.org_model.children())[:-1]))\n",
    "        self.fc = nn.Linear(512, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        bs,c,w,h = x.size()\n",
    "        x = x.view(bs, -1)\n",
    "        out = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T15:32:03.046126Z",
     "start_time": "2021-06-10T15:32:03.035441Z"
    }
   },
   "outputs": [],
   "source": [
    "class build_fn(pl.LightningModule):\n",
    "    def __init__(self, hparams, train_loader=None, val_loader=None):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.model = audio_resnet34()\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def step(self, batch, batch_idx):\n",
    "        x, labels = batch\n",
    "        output = self(x)\n",
    "        loss = self.loss_fn(output, labels)\n",
    "        \n",
    "        logits = nn.functional.softmax(output)\n",
    "        \n",
    "        y_true = list(labels.detach().cpu().numpy())\n",
    "        y_pred = list(logits.detach().cpu().numpy())\n",
    "\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, batch_idx)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, batch_idx)\n",
    "\n",
    "    def epoch_end(self, outputs, state='train'):\n",
    "        loss = 0.0\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        \n",
    "        for i in outputs:\n",
    "            loss += i['loss'].item()\n",
    "            y_true += i['y_true']\n",
    "            y_pred += i['y_pred']\n",
    "            \n",
    "        loss = loss / len(outputs)\n",
    "\n",
    "        self.log(state+'_loss', float(loss), on_epoch=True, prog_bar=True)\n",
    "        self.log(state+'_acc', accuracy_score(y_true, np.argmax(y_pred, axis=-1)), on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(state+'_f1', f1_score(y_true, np.argmax(y_pred, axis=-1), average='weighted'), on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def train_epoch_end(self, outputs):\n",
    "        return self.epoch_end(outputs, state='train')\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        return self.epoch_end(outputs, state='val')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "        scheduler = {'scheduler': torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                                             patience=2, \n",
    "                                                                             mode='min', verbose=True),\n",
    "                     'interval': 'epoch',\n",
    "                     'monitor': 'val_loss'}\n",
    "        return [optimizer], [scheduler]\n",
    "                 \n",
    "    def train_dataloader(self):\n",
    "        return self.train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-09T05:46:03.985Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Using native 16bit precision.\n",
      "\n",
      "  | Name    | Type             | Params\n",
      "---------------------------------------------\n",
      "0 | model   | audio_resnet34   | 21.8 M\n",
      "1 | loss_fn | CrossEntropyLoss | 0     \n",
      "---------------------------------------------\n",
      "21.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.8 M    Total params\n",
      "87.178    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57ab3a225df453a983be55c7b4286f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skf = sklearn.model_selection.StratifiedKFold(n_splits=5, random_state=args['seed'], shuffle=True)\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(skf.split(train_df.values, train_df['accent'])):\n",
    "    trn_df, val_df = train_df.iloc[trn_idx], train_df.iloc[val_idx]\n",
    "    \n",
    "    train_ds = AudioDataset(args, trn_df, train=True, transform=True)\n",
    "    valid_ds = AudioDataset(args, val_df, train=False, transform=False)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=args['batch_num'], shuffle=True, num_workers=4, pin_memory=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_ds, batch_size=args['batch_num'], shuffle=False, num_workers=4, pin_memory=False)\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        filename= '{epoch}-{val_acc:.2f}-{val_loss:.3f}',\n",
    "        monitor='val_loss',\n",
    "        save_top_k=1,\n",
    "        mode='min')\n",
    "    \n",
    "    early_stop_callback = EarlyStopping(monitor='val_loss', \n",
    "                                        patience=4, \n",
    "                                        verbose=True, \n",
    "                                        mode='min')\n",
    "    \n",
    "    trainer = pl.Trainer(\n",
    "        callbacks=[checkpoint_callback, early_stop_callback],\n",
    "        max_epochs=args['epochs'],\n",
    "        deterministic=torch.cuda.is_available(),\n",
    "        gpus=-1 if torch.cuda.is_available() else None,\n",
    "        precision= 16 if args['fp16'] else 32)\n",
    "\n",
    "    pl_model = build_fn(args, train_loader, valid_loader)\n",
    "    \n",
    "    trainer.fit(pl_model)\n",
    "    print(checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T15:32:07.932286Z",
     "start_time": "2021-06-10T15:32:07.924858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/test_npy/1.npy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/test_npy/2.npy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/test_npy/3.npy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset/test_npy/4.npy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset/test_npy/5.npy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       path  id\n",
       "0  ./dataset/test_npy/1.npy   1\n",
       "1  ./dataset/test_npy/2.npy   2\n",
       "2  ./dataset/test_npy/3.npy   3\n",
       "3  ./dataset/test_npy/4.npy   4\n",
       "4  ./dataset/test_npy/5.npy   5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T15:33:28.670330Z",
     "start_time": "2021-06-10T15:33:28.659104Z"
    }
   },
   "outputs": [],
   "source": [
    "class Test_AudioDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, hparams, csv, transform=None):\n",
    "        self.hparams = hparams\n",
    "        self.csv = csv.reset_index(drop=True)\n",
    "        self.aug = Compose([AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "                            TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "                            PitchShift(min_semitones=-4,\n",
    "                                       max_semitones=4, p=0.5),\n",
    "                            Shift(min_fraction=-0.5, max_fraction=0.5, p=0.5)])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "    \n",
    "    def generate_mel(self, audio, sr, n_fft, win_length, hop_length, n_mels):\n",
    "        S = librosa.feature.melspectrogram(y=audio,\n",
    "                                           sr=sr,\n",
    "                                           n_fft=n_fft,\n",
    "                                           win_length=win_length,\n",
    "                                           hop_length=hop_length,\n",
    "                                           n_mels=n_mels)\n",
    "        S = librosa.power_to_db(S, ref=np.max)\n",
    "        S = np.clip((S - self.hparams.min_level_db) / -\n",
    "                    self.hparams.min_level_db, 0, 1)\n",
    "        return S\n",
    "    \n",
    "    def features_extractor(self, audio_path):\n",
    "        audio = np.load(audio_path)\n",
    "        audio = librosa.util.fix_length(audio, self.hparams.min_length)\n",
    "        \n",
    "        if self.transform:\n",
    "            audio = self.aug(audio, sample_rate=self.hparams.sr)\n",
    "\n",
    "        mel = []\n",
    "        for n_fft, win_length in zip(self.hparams.n_fft, self.hparams.win_length):\n",
    "            S = self.generate_mel(audio,\n",
    "                                  self.hparams.sr,\n",
    "                                  n_fft, win_length, self.hparams.hop_length,\n",
    "                                  self.hparams.n_mels)\n",
    "            mel.append(S)\n",
    "        return np.array(mel)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.csv.iloc[index, 0]\n",
    "        mel = self.features_extractor(path)\n",
    "        return torch.tensor(mel, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T15:33:29.943433Z",
     "start_time": "2021-06-10T15:33:29.940498Z"
    }
   },
   "outputs": [],
   "source": [
    "test_ds = Test_AudioDataset(args, test_df, transform=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=256, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T18:14:22.220796Z",
     "start_time": "2021-06-08T18:14:19.258Z"
    }
   },
   "outputs": [],
   "source": [
    "# PATHS = [\"./lightning_logs/version_0/checkpoints/epoch=15-val_acc=0.78-val_loss=0.679.ckpt\",\n",
    "#          \"./lightning_logs/version_1/checkpoints/epoch=8-val_acc=0.72-val_loss=0.782.ckpt\",\n",
    "#          \"./lightning_logs/version_2/checkpoints/epoch=10-val_acc=0.76-val_loss=0.707.ckpt\",\n",
    "#          \"./lightning_logs/version_3/checkpoints/epoch=7-val_acc=0.73-val_loss=0.780.ckpt\",\n",
    "#          \"./lightning_logs/version_4/checkpoints/epoch=10-val_acc=0.76-val_loss=0.676.ckpt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T18:14:22.221227Z",
     "start_time": "2021-06-08T18:14:19.259Z"
    }
   },
   "outputs": [],
   "source": [
    "# PATHS = [\"./lightning_logs/version_5/checkpoints/epoch=16-val_acc=0.80-val_loss=0.651.ckpt\",\n",
    "#          \"./lightning_logs/version_6/checkpoints/epoch=16-val_acc=0.82-val_loss=0.581.ckpt\",\n",
    "#          \"./lightning_logs/version_7/checkpoints/epoch=14-val_acc=0.81-val_loss=0.564.ckpt\",\n",
    "#          \"./lightning_logs/version_8/checkpoints/epoch=15-val_acc=0.84-val_loss=0.492.ckpt\",\n",
    "#          \"./lightning_logs/version_9/checkpoints/epoch=18-val_acc=0.84-val_loss=0.499.ckpt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T15:34:32.369446Z",
     "start_time": "2021-06-10T15:34:32.367075Z"
    }
   },
   "outputs": [],
   "source": [
    "PATHS = [\"./lightning_logs/version_0/checkpoints/epoch=17-val_acc=0.82-val_loss=0.539.ckpt\",\n",
    "         \"./lightning_logs/version_1/checkpoints/epoch=19-val_acc=0.82-val_loss=0.519.ckpt\",\n",
    "         \"./lightning_logs/version_2/checkpoints/epoch=18-val_acc=0.84-val_loss=0.439.ckpt\",\n",
    "         \"./lightning_logs/version_3/checkpoints/epoch=19-val_acc=0.83-val_loss=0.495.ckpt\",\n",
    "         \"./lightning_logs/version_4/checkpoints/epoch=19-val_acc=0.81-val_loss=0.555.ckpt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T15:34:37.353651Z",
     "start_time": "2021-06-10T15:34:37.349181Z"
    }
   },
   "outputs": [],
   "source": [
    "def ensemble_fn(test_loader, ckpt_paths, device):\n",
    "    final_preds = np.zeros(shape=(6100,6))\n",
    "    \n",
    "    for path in ckpt_paths:\n",
    "        model = build_fn.load_from_checkpoint(path)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        pred = []\n",
    "        for _, x in enumerate(tqdm(test_loader)):\n",
    "            x = x.to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(x)\n",
    "                logit = torch.nn.functional.softmax(output)\n",
    "                pred.append(logit.cpu().numpy())        \n",
    "        final_preds += np.concatenate(pred)\n",
    "    return final_preds/len(ckpt_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T15:46:31.958992Z",
     "start_time": "2021-06-10T15:34:40.138171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f254baefd4e428e9026ac1feb59098b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c8ce3a282e486090618f802c2897bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442fb7dfe48e4f4ea11bb6c225186958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2867caf7af514bae9da4ff13c29841e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1415cdc0c7e8406391d71a5251330bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final = ensemble_fn(test_loader, PATHS, 'cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T15:47:59.373530Z",
     "start_time": "2021-06-10T15:47:59.368637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6100, 6)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T15:48:00.316596Z",
     "start_time": "2021-06-10T15:48:00.293515Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(os.path.join(data_dir, 'sample_submission.csv'))\n",
    "sub_df.iloc[:, 1:] = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T15:48:01.097754Z",
     "start_time": "2021-06-10T15:48:01.085947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>africa</th>\n",
       "      <th>australia</th>\n",
       "      <th>canada</th>\n",
       "      <th>england</th>\n",
       "      <th>hongkong</th>\n",
       "      <th>us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.018227</td>\n",
       "      <td>0.036662</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>0.366862</td>\n",
       "      <td>0.032340</td>\n",
       "      <td>0.540008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.006099</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.827213</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.154358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.104748</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.801053</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.077561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.026231</td>\n",
       "      <td>0.008206</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.632881</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.329692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.146706</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>0.005170</td>\n",
       "      <td>0.381705</td>\n",
       "      <td>0.014126</td>\n",
       "      <td>0.449983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    africa  australia    canada   england  hongkong        us\n",
       "0   1  0.018227   0.036662  0.005901  0.366862  0.032340  0.540008\n",
       "1   2  0.005408   0.006099  0.003706  0.827213  0.003215  0.154358\n",
       "2   3  0.104748   0.015337  0.000781  0.801053  0.000520  0.077561\n",
       "3   4  0.026231   0.008206  0.001176  0.632881  0.001815  0.329692\n",
       "4   5  0.146706   0.002311  0.005170  0.381705  0.014126  0.449983"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T15:48:14.750920Z",
     "start_time": "2021-06-10T15:48:14.696613Z"
    }
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv('./infer/resnet34_ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_Server",
   "language": "python",
   "name": "dl_server"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
