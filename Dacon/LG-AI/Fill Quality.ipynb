{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T06:13:21.445609Z",
     "start_time": "2021-02-03T06:13:20.881308Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T07:05:05.790573Z",
     "start_time": "2021-02-02T07:04:59.871900Z"
    }
   },
   "outputs": [],
   "source": [
    "train_err = pd.read_csv('dataset/train_err_data.csv')\n",
    "train_quality = pd.read_csv('dataset/train_quality_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T07:05:24.788620Z",
     "start_time": "2021-02-02T07:05:19.056774Z"
    }
   },
   "outputs": [],
   "source": [
    "test_err = pd.read_csv('dataset/test_err_data.csv')\n",
    "test_quality = pd.read_csv('dataset/test_quality_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T07:06:12.732277Z",
     "start_time": "2021-02-02T07:06:12.645797Z"
    }
   },
   "outputs": [],
   "source": [
    "train_quality = train_quality.drop(['quality_3', 'quality_4'], axis=1)\n",
    "test_quality = test_quality.drop(['quality_3', 'quality_4'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T07:06:47.136067Z",
     "start_time": "2021-02-02T07:06:47.130378Z"
    }
   },
   "outputs": [],
   "source": [
    "fwver_model_dict = {'04.22': 'model_0',\n",
    "                    '04.16': 'model_1',\n",
    "                    '04.33': 'model_2',\n",
    "                    '05.15': 'model_3',\n",
    "                    '03.11': 'model_4',\n",
    "                    '04.82': 'model_5',\n",
    "                    '05.66': 'model_7',\n",
    "                    '04.73': 'model_8'}\n",
    "\n",
    "def case_fwver(x):\n",
    "    try:    \n",
    "        return fwver_model_dict[x[:5]]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T07:06:48.623856Z",
     "start_time": "2021-02-02T07:06:48.478361Z"
    }
   },
   "outputs": [],
   "source": [
    "exist_case = train_quality[['user_id', 'time', 'fwver']].drop_duplicates().reset_index(drop=True)\n",
    "exist_case['model_nm'] = exist_case['fwver'].apply(lambda x: case_fwver(x))\n",
    "\n",
    "\n",
    "test_exist_case = test_quality[['user_id', 'time', 'fwver']].drop_duplicates().reset_index(drop=True)\n",
    "test_exist_case['model_nm'] = test_exist_case['fwver'].apply(lambda x: case_fwver(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T07:07:46.498816Z",
     "start_time": "2021-02-02T07:07:16.804815Z"
    }
   },
   "outputs": [],
   "source": [
    "train_all = pd.concat([train_err, exist_case], axis=0)\n",
    "train_all = train_all.groupby('user_id').apply(pd.DataFrame.sort_values, 'time').reset_index(drop=True)\n",
    "\n",
    "\n",
    "test_all = pd.concat([test_err, test_exist_case], axis=0)\n",
    "test_all = test_all.groupby('user_id').apply(pd.DataFrame.sort_values, 'time').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T07:10:38.655155Z",
     "start_time": "2021-02-02T07:10:37.416691Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = list(train_all.loc[train_all['errtype'].isna()==True].index)\n",
    "test_idx = list(test_all.loc[test_all['errtype'].isna()==True].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T07:11:00.115722Z",
     "start_time": "2021-02-02T07:10:51.921694Z"
    }
   },
   "outputs": [],
   "source": [
    "train_all['fwver'] = train_all.groupby(['user_id','model_nm'])['fwver'].bfill().ffill()\n",
    "train_all['model_nm'] = train_all.groupby(['user_id','fwver'])['model_nm'].bfill().ffill()\n",
    "train_all['errtype'] = train_all.groupby(['user_id','model_nm'])['errtype'].bfill().ffill()\n",
    "train_all['errcode'] = train_all.groupby(['user_id', 'model_nm'])['errcode'].bfill().ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T07:11:08.700538Z",
     "start_time": "2021-02-02T07:11:00.612582Z"
    }
   },
   "outputs": [],
   "source": [
    "test_all['fwver'] = test_all.groupby(['user_id','model_nm'])['fwver'].bfill().ffill()\n",
    "test_all['model_nm'] = test_all.groupby(['user_id','fwver'])['model_nm'].bfill().ffill()\n",
    "test_all['errtype'] = test_all.groupby(['user_id','model_nm'])['errtype'].bfill().ffill()\n",
    "test_all['errcode'] = test_all.groupby(['user_id', 'model_nm'])['errcode'].bfill().ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T07:11:49.159175Z",
     "start_time": "2021-02-02T07:11:49.127379Z"
    }
   },
   "outputs": [],
   "source": [
    "fill_case = train_all.iloc[idx].reset_index(drop=True)\n",
    "test_fill_case = test_all.iloc[test_idx].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T07:13:19.301699Z",
     "start_time": "2021-02-02T07:13:19.024197Z"
    }
   },
   "outputs": [],
   "source": [
    "fill_case.to_csv('./dataset/exist_case.csv', index=False)\n",
    "test_fill_case.to_csv('./dataset/test_exist_case.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T07:15:08.759744Z",
     "start_time": "2021-02-02T07:14:49.909621Z"
    }
   },
   "outputs": [],
   "source": [
    "quality_col = [col for col in train_quality.columns if col.startswith('quality')]\n",
    "\n",
    "def string2num(x):\n",
    "    # (,)( )과 같은 불필요한 데이터 정제\n",
    "    x = re.sub(r',', '', str(x))\n",
    "    if x =='':\n",
    "        return 0\n",
    "    else:\n",
    "        return float(x)\n",
    "    \n",
    "for col in quality_col:\n",
    "    train_quality[col] = train_quality[col].apply(lambda x: string2num(x))\n",
    "    test_quality[col] = test_quality[col].apply(lambda x: string2num(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T07:15:20.820734Z",
     "start_time": "2021-02-02T07:15:19.912032Z"
    }
   },
   "outputs": [],
   "source": [
    "fill_case['time'] = fill_case['time'].apply(lambda x: datetime.strptime(str(x), '%Y%m%d%H%M%S')) \n",
    "test_fill_case['time'] = test_fill_case['time'].apply(lambda x: datetime.strptime(str(x), '%Y%m%d%H%M%S')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T07:16:58.389624Z",
     "start_time": "2021-02-02T07:16:48.045443Z"
    }
   },
   "outputs": [],
   "source": [
    "train_quality['time'] = train_quality['time'].apply(lambda x: datetime.strptime(str(x), '%Y%m%d%H%M%S')) \n",
    "test_quality['time'] = test_quality['time'].apply(lambda x: datetime.strptime(str(x), '%Y%m%d%H%M%S')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T07:17:06.997420Z",
     "start_time": "2021-02-02T07:17:06.727822Z"
    }
   },
   "outputs": [],
   "source": [
    "train_quality = train_quality.drop(['fwver'], axis=1)\n",
    "train_quality = pd.merge(train_quality, fill_case, how='left', on=['user_id', 'time'])\n",
    "\n",
    "test_quality = test_quality.drop(['fwver'], axis=1)\n",
    "test_quality = pd.merge(test_quality, test_fill_case, how='left', on=['user_id', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T07:20:46.385403Z",
     "start_time": "2021-02-02T07:20:46.382655Z"
    }
   },
   "outputs": [],
   "source": [
    "train_quality_missing_col = ['quality_0', 'quality_2', 'quality_5']\n",
    "test_quality_missing_col = ['quality_0', 'quality_1', 'quality_2', 'quality_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T07:21:16.100716Z",
     "start_time": "2021-02-02T07:21:15.866822Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in train_quality_missing_col:\n",
    "    train_quality[col] = train_quality.groupby(['user_id', 'model_nm', 'fwver'])[col].ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T07:21:22.225522Z",
     "start_time": "2021-02-02T07:21:21.935710Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in test_quality_missing_col:\n",
    "    test_quality[col] = test_quality.groupby(['user_id', 'model_nm', 'fwver'])[col].ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-02T07:26:40.628404Z",
     "start_time": "2021-02-02T07:26:27.473204Z"
    }
   },
   "outputs": [],
   "source": [
    "train_quality.to_csv('./dataset/fe_train_quality.csv', index=False)\n",
    "test_quality.to_csv('./dataset/fe_test_quality.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T06:13:29.900279Z",
     "start_time": "2021-02-03T06:13:28.621754Z"
    }
   },
   "outputs": [],
   "source": [
    "train_quality = pd.read_csv('./dataset/fe_train_quality.csv', parse_dates=['time'], infer_datetime_format=True)\n",
    "test_quality =  pd.read_csv('./dataset/fe_test_quality.csv', parse_dates=['time'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T06:13:29.915065Z",
     "start_time": "2021-02-03T06:13:29.901483Z"
    }
   },
   "outputs": [],
   "source": [
    "def describe_by_time(df):\n",
    "    # Day,Min With Logs Interval\n",
    "    log_case = df.groupby(['user_id','time']).size().reset_index(name='cnt')\n",
    "    log_case['shift_time'] = log_case.groupby(['user_id'])['time'].shift(1)\n",
    "    log_case['diff_days'] = log_case.apply(lambda x: (x['time'] - x['shift_time']).days, axis=1)\n",
    "    log_case['diff_mins'] = log_case.apply(lambda x: (x['time'] - x['shift_time']).total_seconds(), axis=1)\n",
    "    log_case['diff_mins'] /= 60\n",
    "    \n",
    "    action_log_interval = log_case.groupby('user_id')['diff_days', 'diff_mins'].agg(['mean', 'std']).reset_index()\n",
    "    action_log_interval.columns = ['user_id']+['Q_{}_{}'.format(i, j) for i, j in action_log_interval.columns[1:]]\n",
    "    action_log_interval = action_log_interval.fillna(0)\n",
    "    \n",
    "    # Per User Log, time Frequency\n",
    "    log_cnt = df.groupby('user_id')['time'].nunique().reset_index(name='Q_log_cnt')\n",
    "    time_cnt = df.groupby(['user_id']).size().reset_index(name='Q_time_cnt')\n",
    "    \n",
    "    # Merge\n",
    "    processed_df = pd.merge(action_log_interval, log_cnt, how='left', on='user_id')\n",
    "    processed_df = pd.merge(processed_df, time_cnt, how='left', on='user_id')\n",
    "    \n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T06:13:35.150499Z",
     "start_time": "2021-02-03T06:13:29.917103Z"
    }
   },
   "outputs": [],
   "source": [
    "Q_time = describe_by_time(train_quality)\n",
    "Q_test_time = describe_by_time(test_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T06:13:35.154243Z",
     "start_time": "2021-02-03T06:13:35.151532Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_polycol(df):\n",
    "    df['errtype'] = df['errtype'].astype('str') \n",
    "    df['errcase'] = df.iloc[:]['errtype'] + '_' + df.iloc[:]['errcode']\n",
    "    df['model_errtype'] = df.iloc[:]['model_nm'] + '_' + df.iloc[:]['errtype']\n",
    "    df['fwver_errcode'] = df.iloc[:]['fwver'] + '_' + df.iloc[:]['errcode']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T06:13:36.205582Z",
     "start_time": "2021-02-03T06:13:35.155336Z"
    }
   },
   "outputs": [],
   "source": [
    "train_quality = make_polycol(train_quality)\n",
    "test_quality = make_polycol(test_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T06:13:51.155363Z",
     "start_time": "2021-02-03T06:13:51.143508Z"
    }
   },
   "outputs": [],
   "source": [
    "errcase_dict = {code:idx for idx, code in enumerate(list(train_quality['errcase'].value_counts()[:50].index))}\n",
    "# model_errtype_dict = {code:idx for idx, code in enumerate(list(train_quality['model_errtype'].value_counts()[:50].index))}\n",
    "# fwver_errcode_dict = {code:idx for idx, code in enumerate(list(train_quality['fwver_errcode'].value_counts()[:50].index))}\n",
    "\n",
    "def case_study(dict_case, x):\n",
    "    try:\n",
    "        return dict_case[x]\n",
    "    except:\n",
    "        return len(dict_case)\n",
    "\n",
    "def make2group(df):\n",
    "    df['errcase'] = df['errcase'].apply(lambda x: case_study(errcase_dict, x))\n",
    "#     df['model_errtype'] = df['model_errtype'].apply(lambda x: case_study(model_errtype_dict, x))\n",
    "#     df['fwver_errcode'] = df['fwver_errcode'].apply(lambda x: case_study(fwver_errcode_dict, x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T06:13:52.072822Z",
     "start_time": "2021-02-03T06:13:51.496116Z"
    }
   },
   "outputs": [],
   "source": [
    "train_quality = make2group(train_quality)\n",
    "test_quality = make2group(test_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T06:13:54.418357Z",
     "start_time": "2021-02-03T06:13:54.413153Z"
    }
   },
   "outputs": [],
   "source": [
    "def side_information(df):\n",
    "    # Errtype\n",
    "    errtype_unum = df.groupby(['user_id'])['errtype'].nunique().reset_index(name='Q_errtype_unum')\n",
    "\n",
    "    # Errcode\n",
    "    errcode_unum = df.groupby(['user_id'])['errcode'].nunique().reset_index(name='Q_errcode_unum')\n",
    "    \n",
    "\n",
    "    # Model_nm\n",
    "    model_unum = df.groupby(['user_id'])['model_nm'].nunique().reset_index(name='Q_model_unum')\n",
    "    \n",
    "#     # Model + Errtype\n",
    "#     merrtype_unum = df.groupby(['user_id'])['model_errtype'].nunique().reset_index(name='Q_merrtype_unum')\n",
    "\n",
    "\n",
    "    # Merge\n",
    "    processed_df = pd.merge(errtype_unum, errcode_unum, how='left', on='user_id')\n",
    "    \n",
    "    processed_df = pd.merge(processed_df, model_unum, how='left', on='user_id')\n",
    "#     processed_df = pd.merge(processed_df, merrtype_unum, how='left', on='user_id')\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T06:13:55.198533Z",
     "start_time": "2021-02-03T06:13:54.768691Z"
    }
   },
   "outputs": [],
   "source": [
    "Q_side = side_information(train_quality)\n",
    "Q_test_side = side_information(test_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T06:14:01.167989Z",
     "start_time": "2021-02-03T06:14:01.164278Z"
    }
   },
   "outputs": [],
   "source": [
    "quality_col = [col for col in train_quality.columns if col.startswith('quality')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T06:24:43.422807Z",
     "start_time": "2021-02-03T06:24:43.406994Z"
    }
   },
   "outputs": [],
   "source": [
    "def quality_information(df):\n",
    "    cumsum_df = df.groupby(['user_id', 'time'])[quality_col].sum().groupby(level=0).cumsum().reset_index()\n",
    "    cumsum_df = cumsum_df.groupby(['user_id'])[quality_col].agg(['mean', 'std']).reset_index()\n",
    "    cumsum_df.columns = ['user_id']+['Qcumsum_{}_{}'.format(i, j) for i, j in cumsum_df.columns[1:]]\n",
    "    \n",
    "    sum_df = df.groupby(['user_id', 'time'])[quality_col].sum().reset_index()\n",
    "    sum_df = sum_df.groupby(['user_id'])[quality_col].agg(['mean', 'std']).reset_index()\n",
    "    sum_df.columns = ['user_id']+['Qsum_{}_{}'.format(i, j) for i, j in sum_df.columns[1:]]\n",
    "    \n",
    "    quality_info = df.groupby(['user_id'])[quality_col].agg(['max', 'min', 'mean', 'std']).reset_index()\n",
    "    quality_info.columns = ['user_id']+['Qavg_{}_{}'.format(i, j) for i, j in quality_info.columns[1:]]\n",
    "    \n",
    "    rolling_df = df.groupby(['user_id'])[quality_col].rolling(12).agg(['mean', 'std']).reset_index()\n",
    "    rolling_df.columns = ['user_id']+['rolling_{}_{}'.format(i, j) for i, j in rolling_df.columns[1:]]\n",
    "    rolling_df = rolling_df.groupby(['user_id']).mean()\n",
    "    \n",
    "    processed_df = pd.merge(cumsum_df, sum_df, how='left', on='user_id')\n",
    "    processed_df = pd.merge(processed_df, quality_info, how='left', on='user_id')\n",
    "    processed_df = pd.merge(processed_df, rolling_df, how='left', on='user_id')\n",
    "#     processed_df = pd.merge(processed_df, sin_df, how='left', on='user_id')\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T06:25:53.654533Z",
     "start_time": "2021-02-03T06:24:43.684048Z"
    }
   },
   "outputs": [],
   "source": [
    "Q_quality = quality_information(train_quality)\n",
    "Q_test_quality = quality_information(test_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T06:26:41.536636Z",
     "start_time": "2021-02-03T06:26:41.511078Z"
    }
   },
   "outputs": [],
   "source": [
    "Q_total = pd.merge(Q_time, Q_side, how='left', on='user_id')\n",
    "Q_total = pd.merge(Q_total, Q_quality, how='left', on='user_id')\n",
    "\n",
    "Q_test_total = pd.merge(Q_test_time, Q_test_side, how='left', on='user_id')\n",
    "Q_test_total = pd.merge(Q_test_total, Q_test_quality, how='left', on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T06:26:43.151898Z",
     "start_time": "2021-02-03T06:26:41.795316Z"
    }
   },
   "outputs": [],
   "source": [
    "Q_total.to_csv('./dataset/train_quality_toal.csv', index=False)\n",
    "Q_test_total.to_csv('./dataset/test_quality_toal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T06:26:27.581800Z",
     "start_time": "2021-02-03T06:26:27.561343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Qcumsum_quality_0_mean</th>\n",
       "      <th>Qcumsum_quality_0_std</th>\n",
       "      <th>Qcumsum_quality_1_mean</th>\n",
       "      <th>Qcumsum_quality_1_std</th>\n",
       "      <th>Qcumsum_quality_2_mean</th>\n",
       "      <th>Qcumsum_quality_2_std</th>\n",
       "      <th>Qcumsum_quality_5_mean</th>\n",
       "      <th>Qcumsum_quality_5_std</th>\n",
       "      <th>Qcumsum_quality_6_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>rolling_quality_8_mean</th>\n",
       "      <th>rolling_quality_8_std</th>\n",
       "      <th>rolling_quality_9_mean</th>\n",
       "      <th>rolling_quality_9_std</th>\n",
       "      <th>rolling_quality_10_mean</th>\n",
       "      <th>rolling_quality_10_std</th>\n",
       "      <th>rolling_quality_11_mean</th>\n",
       "      <th>rolling_quality_11_std</th>\n",
       "      <th>rolling_quality_12_mean</th>\n",
       "      <th>rolling_quality_12_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.476063e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.069045</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.069045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.069045</td>\n",
       "      <td>12.25</td>\n",
       "      <td>9.996428</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076471</td>\n",
       "      <td>5.643772e-02</td>\n",
       "      <td>3.988235</td>\n",
       "      <td>7.901280e-01</td>\n",
       "      <td>-0.023529</td>\n",
       "      <td>5.716582e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>41.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.490116e-08</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.380316e-01</td>\n",
       "      <td>-0.147436</td>\n",
       "      <td>3.515707e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10005</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.242641</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.490116e-08</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.380316e-01</td>\n",
       "      <td>-0.352564</td>\n",
       "      <td>3.468100e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.490116e-08</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.853547e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.879502e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  Qcumsum_quality_0_mean  Qcumsum_quality_0_std  \\\n",
       "0    10000                     0.0               0.000000   \n",
       "1    10002                     1.0               1.069045   \n",
       "2    10004                    -2.0               0.000000   \n",
       "3    10005                    -5.0               7.071068   \n",
       "4    10006                     0.0               0.000000   \n",
       "\n",
       "   Qcumsum_quality_1_mean  Qcumsum_quality_1_std  Qcumsum_quality_2_mean  \\\n",
       "0                     0.0               0.000000                     0.0   \n",
       "1                    -1.0               1.069045                     0.0   \n",
       "2                    -2.0               0.000000                    -2.0   \n",
       "3                    -5.0               7.071068                    -5.0   \n",
       "4                     0.0               0.000000                     0.0   \n",
       "\n",
       "   Qcumsum_quality_2_std  Qcumsum_quality_5_mean  Qcumsum_quality_5_std  \\\n",
       "0               0.000000                    8.00               5.656854   \n",
       "1               1.069045                   12.25               9.996428   \n",
       "2               0.000000                    1.50               0.707107   \n",
       "3               7.071068                    3.00               4.242641   \n",
       "4               0.000000                    8.00               4.000000   \n",
       "\n",
       "   Qcumsum_quality_6_mean  ...  rolling_quality_8_mean  rolling_quality_8_std  \\\n",
       "0                     0.0  ...                     0.0                    0.0   \n",
       "1                    17.0  ...                     0.0                    0.0   \n",
       "2                    41.5  ...                     0.0                    0.0   \n",
       "3                    13.0  ...                     0.0                    0.0   \n",
       "4                     4.0  ...                     0.0                    0.0   \n",
       "\n",
       "   rolling_quality_9_mean  rolling_quality_9_std  rolling_quality_10_mean  \\\n",
       "0                0.000000           0.000000e+00                 6.000000   \n",
       "1                0.076471           5.643772e-02                 3.988235   \n",
       "2                0.000000           1.490116e-08                 2.000000   \n",
       "3                0.000000           1.490116e-08                 5.000000   \n",
       "4                0.000000           1.490116e-08                 4.000000   \n",
       "\n",
       "   rolling_quality_10_std  rolling_quality_11_mean  rolling_quality_11_std  \\\n",
       "0            1.476063e+00                 0.000000            0.000000e+00   \n",
       "1            7.901280e-01                -0.023529            5.716582e-02   \n",
       "2            7.380316e-01                -0.147436            3.515707e-01   \n",
       "3            7.380316e-01                -0.352564            3.468100e-01   \n",
       "4            1.853547e-07                 0.000000            1.879502e-08   \n",
       "\n",
       "   rolling_quality_12_mean  rolling_quality_12_std  \n",
       "0                      0.0                     0.0  \n",
       "1                      0.0                     0.0  \n",
       "2                      0.0                     0.0  \n",
       "3                      0.0                     0.0  \n",
       "4                      0.0                     0.0  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_quality.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Server",
   "language": "python",
   "name": "ml_server"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "426.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
