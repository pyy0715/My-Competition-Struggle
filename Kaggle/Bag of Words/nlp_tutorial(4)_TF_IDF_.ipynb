{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp-tutorial(4)/TF_IDF/.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pyy0715/Kaggle-with-R/blob/master/nlp_tutorial(4)_TF_IDF_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNoj67N4t-yy",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "outputId": "495a42e9-33a1-46d2-fdef-4efafae7469a"
      },
      "source": [
        "# API Token 다운받기\n",
        "# 다운받은 API Token 업로드 하기\n",
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "# json 파일 옮겨주기\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "# Permission Warning 이 일어나지 않도록 \n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "# json 파일 제대로 업로드 됐는지 확인\n",
        "!ls -1ha kaggle.json\n",
        "# 본인이 참가한 모든 대회 보기 \n",
        "!kaggle competitions list\n",
        "# 데이터셋 다운로드 받기 - 링크는 그 대회 'Data'에 있음\n",
        "! kaggle competitions download -c word2vec-nlp-tutorial\n",
        "# 다운로드 된 것들 다 보기 \n",
        "!ls"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1db1ba94-eeca-4e5c-bde3-a321b67ec8df\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-1db1ba94-eeca-4e5c-bde3-a321b67ec8df\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "kaggle.json\n",
            "ref                                                deadline             category            reward  teamCount  userHasEntered  \n",
            "-------------------------------------------------  -------------------  ---------------  ---------  ---------  --------------  \n",
            "digit-recognizer                                   2030-01-01 00:00:00  Getting Started  Knowledge       3115            True  \n",
            "titanic                                            2030-01-01 00:00:00  Getting Started  Knowledge      11285            True  \n",
            "house-prices-advanced-regression-techniques        2030-01-01 00:00:00  Getting Started  Knowledge       4765            True  \n",
            "imagenet-object-localization-challenge             2029-12-31 07:00:00  Research         Knowledge         38           False  \n",
            "competitive-data-science-predict-future-sales      2019-12-31 23:59:00  Playground           Kudos       3263           False  \n",
            "champs-scalar-coupling                             2019-08-28 23:59:00  Featured           $30,000        334           False  \n",
            "recognizing-faces-in-the-wild                      2019-08-01 23:59:00  Playground       Knowledge        219           False  \n",
            "two-sigma-financial-news                           2019-07-15 23:59:00  Featured          $100,000       2927           False  \n",
            "aerial-cactus-identification                       2019-07-08 23:59:00  Playground       Knowledge        733           False  \n",
            "jigsaw-unintended-bias-in-toxicity-classification  2019-06-26 23:59:00  Featured           $65,000       2449           False  \n",
            "data-science-for-good-city-of-los-angeles          2019-06-21 23:59:00  Analytics          $15,000          0           False  \n",
            "instant-gratification                              2019-06-20 23:59:00  Featured            $5,000        975           False  \n",
            "imaterialist-fashion-2019-FGVC6                    2019-06-10 23:59:00  Research             Kudos        195           False  \n",
            "inaturalist-2019-fgvc6                             2019-06-10 23:59:00  Research             Kudos        208           False  \n",
            "freesound-audio-tagging-2019                       2019-06-10 11:59:00  Research            $5,000        808           False  \n",
            "iwildcam-2019-fgvc6                                2019-06-07 23:59:00  Playground           Kudos        323           False  \n",
            "imet-2019-fgvc6                                    2019-06-04 23:59:00  Research             Kudos        498           False  \n",
            "LANL-Earthquake-Prediction                         2019-06-03 23:59:00  Research           $50,000       4484            True  \n",
            "landmark-recognition-2019                          2019-06-03 23:59:00  Research           $25,000        281           False  \n",
            "landmark-retrieval-2019                            2019-06-03 23:59:00  Research           $25,000        144           False  \n",
            "sampleSubmission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Downloading unlabeledTrainData.tsv.zip to /content\n",
            " 35% 9.00M/26.0M [00:05<00:12, 1.46MB/s]\n",
            "100% 26.0M/26.0M [00:05<00:00, 4.75MB/s]\n",
            "Downloading testData.tsv.zip to /content\n",
            " 79% 10.0M/12.6M [00:00<00:00, 103MB/s]\n",
            "100% 12.6M/12.6M [00:00<00:00, 117MB/s]\n",
            "Downloading labeledTrainData.tsv.zip to /content\n",
            " 39% 5.00M/13.0M [00:01<00:01, 4.60MB/s]\n",
            "100% 13.0M/13.0M [00:01<00:00, 10.7MB/s]\n",
            "adc.json\t\t  sample_data\t\tunlabeledTrainData.tsv.zip\n",
            "kaggle.json\t\t  sampleSubmission.csv\n",
            "labeledTrainData.tsv.zip  testData.tsv.zip\n",
            "unzip:  cannot find or open train.zip, train.zip.zip or train.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m46rp29hvIR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c9fa7ec2-f1fe-46e7-a7f2-6e74fe369792"
      },
      "source": [
        "!unzip labeledTrainData.tsv.zip\n",
        "!unzip testData.tsv.zip"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  labeledTrainData.tsv.zip\n",
            "  inflating: labeledTrainData.tsv    \n",
            "Archive:  testData.tsv.zip\n",
            "  inflating: testData.tsv            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwszywkkvIVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# 레이블인 sentiment 가 있는 학습 데이터\n",
        "train = pd.read_csv('labeledTrainData.tsv',header=0, delimiter='\\t', quoting=3)\n",
        "\n",
        "# 레이블이 없는 테스트 데이터\n",
        "test = pd.read_csv('testData.tsv', header=0, delimiter='\\t', quoting=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5RxlNMewqmA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7daab242-b2f2-426e-aa0e-9fb64c1d725b"
      },
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 3)\n",
            "(25000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLvsVMsYwqon",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e98fb3f6-1984-408b-a5c3-a9863342dd3b"
      },
      "source": [
        "train['sentiment'].value_counts()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    12500\n",
              "0    12500\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFnBar08wqrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "from multiprocessing import Pool\n",
        "\n",
        "class KaggleWord2VecUtility(object):\n",
        "\n",
        "    @staticmethod\n",
        "    def review_to_wordlist(review, remove_stopwords=False):\n",
        "        # 1. HTML 제거\n",
        "        review_text = BeautifulSoup(review, \"html.parser\").get_text()\n",
        "        # 2. 특수문자를 공백으로 바꿔줌\n",
        "        review_text = re.sub('[^a-zA-Z]', ' ', review_text)\n",
        "        # 3. 소문자로 변환 후 나눈다.\n",
        "        words = review_text.lower().split()\n",
        "        # 4. 불용어 제거\n",
        "        if remove_stopwords:\n",
        "            stops = set(stopwords.words('english'))\n",
        "            words = [w for w in words if not w in stops]\n",
        "        # 5. 어간추출\n",
        "        stemmer = SnowballStemmer('english')\n",
        "        words = [stemmer.stem(w) for w in words]\n",
        "        # 6. 리스트 형태로 반환\n",
        "        return(words)\n",
        "\n",
        "    @staticmethod\n",
        "    def review_to_join_words( review, remove_stopwords=False ):\n",
        "        words = KaggleWord2VecUtility.review_to_wordlist(\\\n",
        "            review, remove_stopwords=False)\n",
        "        join_words = ' '.join(words)\n",
        "        return join_words\n",
        "\n",
        "    @staticmethod\n",
        "    def review_to_sentences( review, remove_stopwords=False ):\n",
        "        # punkt tokenizer를 로드한다.\n",
        "        \"\"\"\n",
        "        이 때, pickle을 사용하는데\n",
        "        pickle을 통해 값을 저장하면 원래 변수에 연결 된 참조값 역시 저장된다.\n",
        "        저장된 pickle을 다시 읽으면 변수에 연결되었던\n",
        "        모든 레퍼런스가 계속 참조 상태를 유지한다.\n",
        "        \"\"\"\n",
        "        tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "        # 1. nltk tokenizer를 사용해서 단어로 토큰화 하고 공백 등을 제거한다.\n",
        "        raw_sentences = tokenizer.tokenize(review.strip())\n",
        "        # 2. 각 문장을 순회한다.\n",
        "        sentences = []\n",
        "        for raw_sentence in raw_sentences:\n",
        "            # 비어있다면 skip\n",
        "            if len(raw_sentence) > 0:\n",
        "                # 태그제거, 알파벳문자가 아닌 것은 공백으로 치환, 불용어제거\n",
        "                sentences.append(\\\n",
        "                    KaggleWord2VecUtility.review_to_wordlist(\\\n",
        "                    raw_sentence, remove_stopwords))\n",
        "        return sentences\n",
        "\n",
        "\n",
        "    # 참고 : https://gist.github.com/yong27/7869662\n",
        "    # http://www.racketracer.com/2016/07/06/pandas-in-parallel/\n",
        "    # 속도 개선을 위해 멀티 스레드로 작업하도록\n",
        "    @staticmethod\n",
        "    def _apply_df(args):\n",
        "        df, func, kwargs = args\n",
        "        return df.apply(func, **kwargs)\n",
        "\n",
        "    @staticmethod\n",
        "    def apply_by_multiprocessing(df, func, **kwargs):\n",
        "        # 키워드 항목 중 workers 파라메터를 꺼냄\n",
        "        workers = kwargs.pop('workers')\n",
        "        # 위에서 가져온 workers 수로 프로세스 풀을 정의\n",
        "        pool = Pool(processes=workers)\n",
        "        # 실행할 함수와 데이터프레임을 워커의 수 만큼 나눠 작업\n",
        "        result = pool.map(KaggleWord2VecUtility._apply_df, [(d, func, kwargs)\n",
        "                for d in np.array_split(df, workers)])\n",
        "        pool.close()\n",
        "        # 작업 결과를 합쳐서 반환\n",
        "        return pd.concat(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM0eazV7xoWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def review_to_words( raw_review ):\n",
        "    review_text = BeautifulSoup(raw_review, 'html.parser').get_text()\n",
        "    review_text = wordnet_lemmatizer.lemmatize(review_text)\n",
        "    return review_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YhS7KLKyA9Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "c8636952-c342-4142-914d-44cb726a1cf5"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QvIuoZYwqtu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a860103d-b8b4-42b3-e568-c8feb1bf35ac"
      },
      "source": [
        "# 학습데이터를 전처리 한다.\n",
        "%time train['review_clean'] = KaggleWord2VecUtility.apply_by_multiprocessing(\\\n",
        "    train['review'], review_to_words, workers=4)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 107 ms, sys: 130 ms, total: 237 ms\n",
            "Wall time: 7.38 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdSz6HXSxnjp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "39b3bd6e-9b7b-4c90-b812-7604a37d61bd"
      },
      "source": [
        "# 학습데이터와 동일하게 테스트 데이터에 대해서도 전처리 한다.\n",
        "%time test['review_clean'] = KaggleWord2VecUtility.apply_by_multiprocessing(\\\n",
        "    test['review'], review_to_words, workers=4)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 119 ms, sys: 123 ms, total: 242 ms\n",
            "Wall time: 8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImEDx7KTxcSS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "efc9e8ae-f889-423c-faff-5f2952eb6e32"
      },
      "source": [
        "# 전처리한 학습 데이터 10개만을 불러와서 본다.\n",
        "train['review_clean'][:10]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    \"With all this stuff going down at the moment ...\n",
              "1    \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
              "2    \"The film starts with a manager (Nicholas Bell...\n",
              "3    \"It must be assumed that those who praised thi...\n",
              "4    \"Superbly trashy and wondrously unpretentious ...\n",
              "5    \"I dont know why people think this is such a b...\n",
              "6    \"This movie could have been very good, but com...\n",
              "7    \"I watched this video at a friend's house. I'm...\n",
              "8    \"A friend of mine bought this film for £1, and...\n",
              "9    \"This movie is full of references. Like \\\"Mad ...\n",
              "Name: review_clean, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm6YIWUnxcU4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "b8b2870c-cefe-4799-8ee9-0a2220809c32"
      },
      "source": [
        "# 전처리한 테스트 데이터 10개만을 불러와서 본다.\n",
        "test['review_clean'][:10]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    \"Naturally in a film who's main themes are of ...\n",
              "1    \"This movie is a disaster within a disaster fi...\n",
              "2    \"All in all, this is a movie for kids. We saw ...\n",
              "3    \"Afraid of the Dark left me with the impressio...\n",
              "4    \"A very accurate depiction of small time mob l...\n",
              "5    \"...as valuable as King Tut's tomb! (OK, maybe...\n",
              "6    \"This has to be one of the biggest misfires ev...\n",
              "7    \"This is one of those movies I watched, and wo...\n",
              "8    \"The worst movie i've seen in years (and i've ...\n",
              "9    \"Five medical students (Kevin Bacon, David Lab...\n",
              "Name: review_clean, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zleuvnigxcXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train과 X_test에 리뷰 데이터를 담아주고 이 데이터를 TF-IDF를 통해 임베딩(벡터화)해본다. \n",
        "X_train = train['review_clean']\n",
        "X_test = test['review_clean']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iC5grTZyYUL",
        "colab_type": "text"
      },
      "source": [
        "# TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVWNAuRyyik-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "fc29a536-71a5-4cd4-cc0d-cf8ad73d164c"
      },
      "source": [
        "nltk.download('words')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFhRCkdkxcaE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "10c52b0d-90c7-4d56-cb91-6550fde7a2c8"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk.corpus import words\n",
        "\n",
        "vectorizer = CountVectorizer(analyzer = 'word', \n",
        "                             lowercase = True,\n",
        "                             tokenizer = None,\n",
        "                             preprocessor = None,\n",
        "                             stop_words = 'english',\n",
        "                             min_df = 2, # 토큰이 나타날 최소 문서 개수로 오타나 자주 나오지 않는 특수한 전문용어 제거에 좋다. \n",
        "                             ngram_range=(1, 3),\n",
        "                             vocabulary = set(words.words()), # nltk의 words를 사용하거나 문서 자체의 사전을 만들거나 선택한다. \n",
        "                             max_features = 90000\n",
        "                            )\n",
        "vectorizer"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=90000, min_df=2,\n",
              "                ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None,\n",
              "                vocabulary={'A', 'Aani', 'Aaron', 'Aaronic', 'Aaronical',\n",
              "                            'Aaronite', 'Aaronitic', 'Aaru', 'Ab', 'Ababdeh',\n",
              "                            'Ababua', 'Abadite', 'Abama', 'Abanic', 'Abantes',\n",
              "                            'Abarambo', 'Abaris', 'Abasgi', 'Abassin', 'Abatua',\n",
              "                            'Abba', 'Abbadide', 'Abbasside', 'Abbie', 'Abby',\n",
              "                            'Abderian', 'Abderite', 'Abdiel', 'Abdominales',\n",
              "                            'Abe', ...})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HYLu1MCyhxA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "3dbfc846-63ad-4fd3-cf78-4620a31560f4"
      },
      "source": [
        "pipeline = Pipeline([\n",
        "    ('vect', vectorizer),\n",
        "    ('tfidf', TfidfTransformer(smooth_idf = False)),\n",
        "])  \n",
        "pipeline"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=90000, min_df=2,\n",
              "                                 ngram_range=(1, 3), preprocessor=None,\n",
              "                                 stop_words='english', strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None,\n",
              "                                 vocabula...\n",
              "                                             'Aaronical', 'Aaronite',\n",
              "                                             'Aaronitic', 'Aaru', 'Ab',\n",
              "                                             'Ababdeh', 'Ababua', 'Abadite',\n",
              "                                             'Abama', 'Abanic', 'Abantes',\n",
              "                                             'Abarambo', 'Abaris', 'Abasgi',\n",
              "                                             'Abassin', 'Abatua', 'Abba',\n",
              "                                             'Abbadide', 'Abbasside', 'Abbie',\n",
              "                                             'Abby', 'Abderian', 'Abderite',\n",
              "                                             'Abdiel', 'Abdominales', 'Abe', ...})),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=False,\n",
              "                                  sublinear_tf=False, use_idf=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-7Fw5KTxccq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "138d1a6b-a028-4245-d4ec-20ea81839a2f"
      },
      "source": [
        "%time X_train_tfidf_vector = pipeline.fit_transform(X_train)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.71 s, sys: 60.7 ms, total: 6.77 s\n",
            "Wall time: 6.79 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:1278: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  idf = np.log(n_samples / df) + 1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldmdKxMZxcfP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "0e63d7be-907a-4882-f6d9-0be9ddf1d5d0"
      },
      "source": [
        "vocab = vectorizer.get_feature_names()\n",
        "print(len(vocab))\n",
        "vocab[:10]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "235892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A',\n",
              " 'Aani',\n",
              " 'Aaron',\n",
              " 'Aaronic',\n",
              " 'Aaronical',\n",
              " 'Aaronite',\n",
              " 'Aaronitic',\n",
              " 'Aaru',\n",
              " 'Ab',\n",
              " 'Ababdeh']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9iU_ODewqwn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "ea66a6ca-7959-4d52-9649-97a12b5a37e5"
      },
      "source": [
        "%time X_test_tfidf_vector = pipeline.fit_transform(X_test)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.48 s, sys: 33 ms, total: 6.52 s\n",
            "Wall time: 6.52 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:1278: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  idf = np.log(n_samples / df) + 1\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OnKbeXwuMDJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "669714d4-2d71-4b6f-a248-33420d7bfb20"
      },
      "source": [
        "dist = np.sum(X_train_tfidf_vector, axis=0)\n",
        "    \n",
        "for tag, count in zip(vocab, dist):\n",
        "    print(count, tag)\n",
        "    \n",
        "pd.DataFrame(dist, columns=vocab)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]] A\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>Aani</th>\n",
              "      <th>Aaron</th>\n",
              "      <th>Aaronic</th>\n",
              "      <th>Aaronical</th>\n",
              "      <th>Aaronite</th>\n",
              "      <th>Aaronitic</th>\n",
              "      <th>Aaru</th>\n",
              "      <th>Ab</th>\n",
              "      <th>Ababdeh</th>\n",
              "      <th>Ababua</th>\n",
              "      <th>Abadite</th>\n",
              "      <th>Abama</th>\n",
              "      <th>Abanic</th>\n",
              "      <th>Abantes</th>\n",
              "      <th>Abarambo</th>\n",
              "      <th>Abaris</th>\n",
              "      <th>Abasgi</th>\n",
              "      <th>Abassin</th>\n",
              "      <th>Abatua</th>\n",
              "      <th>Abba</th>\n",
              "      <th>Abbadide</th>\n",
              "      <th>Abbasside</th>\n",
              "      <th>Abbie</th>\n",
              "      <th>Abby</th>\n",
              "      <th>Abderian</th>\n",
              "      <th>Abderite</th>\n",
              "      <th>Abdiel</th>\n",
              "      <th>Abdominales</th>\n",
              "      <th>Abe</th>\n",
              "      <th>Abel</th>\n",
              "      <th>Abelia</th>\n",
              "      <th>Abelian</th>\n",
              "      <th>Abelicea</th>\n",
              "      <th>Abelite</th>\n",
              "      <th>Abelmoschus</th>\n",
              "      <th>Abelonian</th>\n",
              "      <th>Abencerrages</th>\n",
              "      <th>Aberdeen</th>\n",
              "      <th>Aberdonian</th>\n",
              "      <th>...</th>\n",
              "      <th>zymic</th>\n",
              "      <th>zymin</th>\n",
              "      <th>zymite</th>\n",
              "      <th>zymogen</th>\n",
              "      <th>zymogene</th>\n",
              "      <th>zymogenesis</th>\n",
              "      <th>zymogenic</th>\n",
              "      <th>zymogenous</th>\n",
              "      <th>zymoid</th>\n",
              "      <th>zymologic</th>\n",
              "      <th>zymological</th>\n",
              "      <th>zymologist</th>\n",
              "      <th>zymology</th>\n",
              "      <th>zymolyis</th>\n",
              "      <th>zymolysis</th>\n",
              "      <th>zymolytic</th>\n",
              "      <th>zymome</th>\n",
              "      <th>zymometer</th>\n",
              "      <th>zymomin</th>\n",
              "      <th>zymophore</th>\n",
              "      <th>zymophoric</th>\n",
              "      <th>zymophosphate</th>\n",
              "      <th>zymophyte</th>\n",
              "      <th>zymoplastic</th>\n",
              "      <th>zymoscope</th>\n",
              "      <th>zymosimeter</th>\n",
              "      <th>zymosis</th>\n",
              "      <th>zymosterol</th>\n",
              "      <th>zymosthenic</th>\n",
              "      <th>zymotechnic</th>\n",
              "      <th>zymotechnical</th>\n",
              "      <th>zymotechnics</th>\n",
              "      <th>zymotechny</th>\n",
              "      <th>zymotic</th>\n",
              "      <th>zymotically</th>\n",
              "      <th>zymotize</th>\n",
              "      <th>zymotoxic</th>\n",
              "      <th>zymurgy</th>\n",
              "      <th>zythem</th>\n",
              "      <th>zythum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 235892 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     A  Aani  Aaron  Aaronic  ...  zymotoxic  zymurgy  zythem  zythum\n",
              "0  0.0   0.0    0.0      0.0  ...        0.0      0.0     0.0     0.0\n",
              "\n",
              "[1 rows x 235892 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNp1noHiuMFo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "32d83d3a-1618-4a0a-bd99-aa2d5f46bb31"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 랜덤포레스트 분류기를 사용\n",
        "forest = RandomForestClassifier(\n",
        "    n_estimators = 100, n_jobs = -1, random_state=2018)\n",
        "forest"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=2018, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zaY1znduMIA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "26fcb909-2758-4a6e-f641-363753281c86"
      },
      "source": [
        "%time forest = forest.fit(X_train_tfidf_vector, train['sentiment'])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 40s, sys: 209 ms, total: 2min 40s\n",
            "Wall time: 1min 21s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46UOTau61SiS",
        "colab_type": "text"
      },
      "source": [
        "# Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXJYGImz1Ogn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoGGjilG1OpB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bbd7b75f-08c1-4636-fcb0-7eb18f69d20f"
      },
      "source": [
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=2018)\n",
        "\n",
        "%time score = np.mean(cross_val_score(\\\n",
        "    forest, X_train_tfidf_vector, \\\n",
        "    train['sentiment'], cv=k_fold, scoring='roc_auc', n_jobs=-1))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 72.8 ms, sys: 61.1 ms, total: 134 ms\n",
            "Wall time: 5min 19s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0TBaVo51OsD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08766b54-f98b-40a1-cf2a-7a01d06967a4"
      },
      "source": [
        "# 0.92149\n",
        "'{:,.5f}'.format(score)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.92051'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-tp6on0-TBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bef579b5-9df8-49b6-943c-48fcfafdd771"
      },
      "source": [
        "%time result = forest.predict(X_test_tfidf_vector)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.93 s, sys: 17.9 ms, total: 1.95 s\n",
            "Wall time: 1.04 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BDb8gR2-TEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2fb8a271-acbf-4dd7-ea17-7284abc8cd75"
      },
      "source": [
        "result[:10]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 1, 1, 0, 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKQ7LeIM-TGe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "2803ef2a-eab5-4289-d60a-3701733be626"
      },
      "source": [
        "output = pd.DataFrame(data={'id':test['id'], 'sentiment':result})\n",
        "output.head()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"12311_10\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"8348_2\"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"5828_4\"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"7186_2\"</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"12128_7\"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  sentiment\n",
              "0  \"12311_10\"          1\n",
              "1    \"8348_2\"          0\n",
              "2    \"5828_4\"          0\n",
              "3    \"7186_2\"          0\n",
              "4   \"12128_7\"          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLTS-jhV-TJn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "fb43bcde-17bc-4236-8a49-9f220803ecb0"
      },
      "source": [
        "output_sentiment = output['sentiment'].value_counts()\n",
        "print(output_sentiment[0] - output_sentiment[1])\n",
        "output_sentiment"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-378\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    12689\n",
              "0    12311\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5kVxcHc-eyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output.to_csv('tutorial_4_tfidf_{0:.5f}.csv'.format(score), index=False, quoting=3)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
